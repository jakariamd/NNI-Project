{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559a9102",
   "metadata": {},
   "source": [
    "# Load Pretrained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63519f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from nni.compression.pytorch.speedup import ModelSpeedup\n",
    "from nni.compression.pytorch.utils import count_flops_params\n",
    "import time\n",
    "\n",
    "from mnist_model import Net, train, test, device, optimizer_scheduler_generator, trainer, test_trt\n",
    "\n",
    "# Load pretrained model\n",
    "model = torch.load(\"mnist_cnn.pt\")\n",
    "model.eval()\n",
    "\n",
    "# show the model stbructure, note that pruner will wrap the model layer.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4435816",
   "metadata": {},
   "source": [
    "### Performance and statistics of pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65e18e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 9919/10000 (99.19%)\n",
      "\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+----------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs   | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+----------+---------+\n",
      "|   0   | conv1 | Conv2d | (32, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 32, 26, 26) |  194688  |   320   |\n",
      "|   1   | conv2 | Conv2d | (64, 32, 3, 3) | (3, 32, 26, 26) | (3, 64, 24, 24) | 10616832 |  18496  |\n",
      "|   2   | fc1   | Linear |  (128, 9216)   |    (3, 9216)    |     (3, 128)    | 1179648  | 1179776 |\n",
      "|   3   | fc2   | Linear |   (10, 128)    |     (3, 128)    |     (3, 10)     |   1280   |   1290  |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+----------+---------+\n",
      "FLOPs total: 11992448\n",
      "#Params total: 1199882\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, Test-time:  1.6234s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "pre_best_acc = test(model, device)\n",
    "pre_test_time = time.time() - start\n",
    "\n",
    "pre_flops, pre_params, _ = count_flops_params(model, torch.randn([3, 1, 28, 28]).to(device))\n",
    "print(f'Pretrained model FLOPs {pre_flops/1e6:.2f} M, #Params: {pre_params/1e6:.2f}M, Accuracy: {pre_best_acc: .2f}%, Test-time: {pre_test_time: .4f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba20bd",
   "metadata": {},
   "source": [
    "# Quantizing Model  with QAT Quantizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68fb9e4",
   "metadata": {},
   "source": [
    "## Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c72f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining  configuration List\n",
    "config_list = [{\n",
    "    'quant_types': ['input', 'weight'],\n",
    "    'quant_bits': {'input': 8, 'weight': 8},\n",
    "    'op_types': ['Conv2d']\n",
    "}, {\n",
    "    'quant_types': ['input', 'weight'],\n",
    "    'quant_bits': {'input': 8, 'weight': 8},\n",
    "    'op_names': ['fc1', 'fc2']\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7431a5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): QuantizerModuleWrapper(\n",
       "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (conv2): QuantizerModuleWrapper(\n",
       "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): QuantizerModuleWrapper(\n",
       "    (module): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc2): QuantizerModuleWrapper(\n",
       "    (module): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nni.algorithms.compression.pytorch.quantization import QAT_Quantizer\n",
    "dummy_input = torch.rand(3, 1, 28, 28).to(device)\n",
    "optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "quantizer = QAT_Quantizer(model, config_list, optimizer, dummy_input)\n",
    "quantizer.compress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03805b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0357, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0353, Accuracy: 9910/10000 (99.10%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0297, Accuracy: 9905/10000 (99.05%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Finetune the model \n",
    "total_epoch = 3  \n",
    "optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "for epoch in range(1, total_epoch + 1):\n",
    "        train(model, device, optimizer=optimizer, epoch=epoch)\n",
    "        test(model, device)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fd4bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-10 23:47:38] \u001b[32mModel state_dict saved to ./log/mnist_model.pth\u001b[0m\n",
      "[2022-10-10 23:47:38] \u001b[32mMask dict saved to ./log/mnist_calibration.pth\u001b[0m\n",
      "calibration_config:  {'conv1': {'weight_bits': 8, 'weight_scale': tensor([0.0036], device='cuda:0'), 'weight_zero_point': tensor([140.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': -0.4242129623889923, 'tracked_max_input': 2.821486711502075}, 'conv2': {'weight_bits': 8, 'weight_scale': tensor([0.0029], device='cuda:0'), 'weight_zero_point': tensor([135.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 3.0494697093963623}, 'fc1': {'weight_bits': 8, 'weight_scale': tensor([0.0014], device='cuda:0'), 'weight_zero_point': tensor([116.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 4.538718223571777}, 'fc2': {'weight_bits': 8, 'weight_scale': tensor([0.0033], device='cuda:0'), 'weight_zero_point': tensor([157.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 18.110979080200195}}\n"
     ]
    }
   ],
   "source": [
    "## export model and get calibration_config\n",
    "\n",
    "model_path = \"./log/mnist_model.pth\"\n",
    "calibration_path = \"./log/mnist_calibration.pth\"\n",
    "calibration_config = quantizer.export_model(model_path, calibration_path)\n",
    "\n",
    "print(\"calibration_config: \", calibration_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "844b6d4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## build tensorRT engine to make a real speedup\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnni\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization_speedup\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelSpeedupTensorRT\n\u001b[1;32m      3\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\n\u001b[1;32m      4\u001b[0m engine \u001b[38;5;241m=\u001b[39m ModelSpeedupTensorRT(model, input_shape, config\u001b[38;5;241m=\u001b[39mcalibration_config, batchsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nni/compression/pytorch/quantization_speedup/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Licensed under the MIT license.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrated_tensorrt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CalibrateType, ModelSpeedupTensorRT\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nni/compression/pytorch/quantization_speedup/integrated_tensorrt.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frontend_to_onnx \u001b[38;5;28;01mas\u001b[39;00m fonnx\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m calibrator \u001b[38;5;28;01mas\u001b[39;00m calibrator\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trt_pycuda \u001b[38;5;28;01mas\u001b[39;00m common\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModelSpeedup\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nni/compression/pytorch/quantization_speedup/calibrator.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorrt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtrt\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpycuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdriver\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[1;32m      9\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCalibrator\u001b[39;00m(trt\u001b[38;5;241m.\u001b[39mIInt8Calibrator):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycuda'"
     ]
    }
   ],
   "source": [
    "## build tensorRT engine to make a real speedup\n",
    "from nni.compression.pytorch.quantization_speedup import ModelSpeedupTensorRT\n",
    "input_shape = (3, 1, 28, 28)\n",
    "engine = ModelSpeedupTensorRT(model, input_shape, config=calibration_config, batchsize=64)\n",
    "engine.compress()\n",
    "test_trt(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ab23e",
   "metadata": {},
   "source": [
    "from nni.compression.pytorch.pruning import ADMMPruner\n",
    "from nni.compression.pytorch.pruning import ActivationMeanRankPruner\n",
    "from nni.compression.pytorch.speedup import ModelSpeedup\n",
    "import nni\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def pruner_function(config_list):\n",
    "\n",
    "    model = torch.load(\"mnist_cnn.pt\")\n",
    "    model.eval()\n",
    "\n",
    "    traced_optimizer = nni.trace(optim.Adadelta)(model.parameters(), lr=1.0)\n",
    "    criterion = F.nll_loss\n",
    "    \n",
    "    # Using ADMMPruner to prune the model and generate the masks.\n",
    "    pruner = ADMMPruner(model, config_list, trainer, traced_optimizer, criterion, iterations=5, training_epochs=1, granularity='coarse-grained')\n",
    "    \n",
    "    # pruner = ActivationMeanRankPruner(model, config_list, trainer, traced_optimizer, criterion, training_batches=20)\n",
    "    \n",
    "    # show the wrapped model structure, `PrunerModuleWrapper` have wrapped the layers that configured in the config_list.\n",
    "    #print(model)\n",
    "\n",
    "    # compress the model and generate the masks\n",
    "    _, masks = pruner.compress()\n",
    "\n",
    "    # show the masks sparsity\n",
    "    print(\"Showing the masks sparsity\")\n",
    "    for name, mask in masks.items():\n",
    "        print(name, ' sparsity : ', '{:.2}'.format(mask['weight'].sum() / mask['weight'].numel()))\n",
    "\n",
    "\n",
    "    # need to unwrap the model, if the model is wrapped before speedup\n",
    "    pruner._unwrap_model()\n",
    "\n",
    "    # speedup the model, for more information about speedup, please refer :doc:`pruning_speedup`.\n",
    "    ModelSpeedup(model, torch.rand(3, 1, 28, 28).to(device), masks).speedup_model()\n",
    "\n",
    "    #print(\"Model after speedup\")\n",
    "    #print(model)\n",
    "\n",
    "    optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "    \n",
    "    # fine- tuning model compacted model\n",
    "    # tuning and evaluate the model on MNIST dataset\n",
    "    total_epoch = 3\n",
    "    \n",
    "    for epoch in range(1, total_epoch + 1):\n",
    "        train(model, device, optimizer=optimizer, epoch=epoch)\n",
    "        test(model, device)\n",
    "        scheduler.step()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f903070",
   "metadata": {},
   "source": [
    "def Perfomance_function(model):\n",
    "    print(\"Model after speedup\")\n",
    "    print(model)\n",
    "    \n",
    "    start = time.time()\n",
    "    best_acc = test(model, device)\n",
    "    test_time = time.time() - start\n",
    "\n",
    "    flops, params, _ = count_flops_params(model, torch.randn([3, 1, 28, 28]).to(device))\n",
    "\n",
    "    print(f'Pretrained model FLOPs {pre_flops/1e6:.2f} M, #Params: {pre_params/1e6:.2f}M, Accuracy: {pre_best_acc: .2f}%, , Test-time: {pre_test_time: .4f}s')\n",
    "    print(f'Finetuned model FLOPs {flops/1e6:.2f} M, #Params: {params/1e6:.2f}M, Accuracy: {best_acc: .2f}%, Test-time: {test_time: .4f}s, Speed-up: {pre_test_time/test_time: .2f}x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1029e382",
   "metadata": {},
   "source": [
    "## ADMM Configuration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b555e5aa",
   "metadata": {},
   "source": [
    "config_list = [{\n",
    "    'sparsity_per_layer': 0.50,\n",
    "    'op_types': ['Linear', 'Conv2d']\n",
    "}, {\n",
    "    'exclude': True,\n",
    "    'op_names': ['fc2']\n",
    "}]\n",
    "\n",
    "\n",
    "pruned_model = pruner_function(config_list=config_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b55cad",
   "metadata": {},
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae4033",
   "metadata": {},
   "source": [
    "## ADMM Configuration 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad16c399",
   "metadata": {},
   "source": [
    "config_list = [{\n",
    "    'op_types': ['Conv2d'],\n",
    "    'total_sparsity': 0.5\n",
    "    }, {\n",
    "    'op_names': ['Linear'],\n",
    "    'total_sparsity': 0.8\n",
    "    },\n",
    "    {\n",
    "    'exclude': True,\n",
    "    'op_names': ['fc2']\n",
    "}]\n",
    "\n",
    "\n",
    "pruned_model = pruner_function(config_list=config_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc19d54",
   "metadata": {},
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
