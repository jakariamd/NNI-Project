{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559a9102",
   "metadata": {},
   "source": [
    "# Define Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63519f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from nni.compression.pytorch.speedup import ModelSpeedup\n",
    "from nni.compression.pytorch.utils import count_flops_params\n",
    "import time\n",
    "\n",
    "from mnist_model import Net, train, test, device, optimizer_scheduler_generator\n",
    "\n",
    "# define the model\n",
    "model = Net().to(device)\n",
    "\n",
    "# show the model stbructure, note that pruner will wrap the model layer.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9108c0",
   "metadata": {},
   "source": [
    "### Pre-train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e585c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302562\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.387486\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.645417\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.684264\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.377084\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.358574\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.193809\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.441934\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.295871\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.100338\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.248852\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.285566\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.350468\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.137451\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.351539\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.142469\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.202928\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.354875\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.258129\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.086925\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.201867\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.106909\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.142805\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.226569\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.259774\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.485067\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.057770\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.122319\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.076082\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.239135\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.106793\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.104809\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.251241\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.222986\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.236928\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.112860\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.202803\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.284726\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.091697\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.134383\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.058482\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.246231\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.257401\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.029214\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.122723\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.031977\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.070002\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.179029\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.170989\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.249173\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.173041\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.095565\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.069863\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.090455\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.135240\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.095651\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.164363\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.189009\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.154305\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.073363\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.091394\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.042411\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.429020\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.154202\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.068145\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.349466\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.169415\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.050364\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.046071\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.105113\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.069679\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.204634\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.035635\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.020276\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.123109\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.078302\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.208058\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.059463\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.017046\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.079688\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.102426\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.135093\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.080846\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.106606\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.093099\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.130921\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.114403\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.107601\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.236367\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.133819\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.059127\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.096290\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.051787\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.111814\n",
      "\n",
      "Test set: Average loss: 0.0482, Accuracy: 9838/10000 (98.38%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.130294\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.038809\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.088749\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.172382\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.034975\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.069647\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.086705\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.152281\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.040612\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.013834\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.031819\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.053630\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.008421\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.054225\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.025008\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.017757\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.170413\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.045098\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.097629\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.041273\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.054837\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.026837\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.165114\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.016583\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.213065\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.001288\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.071131\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.088119\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.059641\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.043732\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.023384\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.026037\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.100195\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.017996\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.057878\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.036774\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.026047\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.073441\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.020068\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.265180\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.071198\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.046281\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.056354\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.028538\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.064136\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.179549\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.169971\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.171558\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.031695\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.020497\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.002732\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.079044\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.027362\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.099982\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.148411\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.062760\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.002994\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.038364\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.098426\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.030193\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.042690\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.029166\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.059544\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.058450\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.053080\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.105434\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.056415\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.004709\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.020412\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.018218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.145454\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.008193\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.087021\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.112213\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.068100\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.218290\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.193344\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.033637\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.030697\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.046368\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.009264\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.084315\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.007126\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.191788\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.225458\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.044964\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.006413\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.082441\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.013870\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.130606\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.015724\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.044074\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.031224\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.043524\n",
      "\n",
      "Test set: Average loss: 0.0335, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.087738\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.044642\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.103027\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.049887\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.024352\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.106576\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.015684\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.016540\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.043143\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.010419\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.046227\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.013262\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.066879\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.024733\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.048764\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.034967\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.011324\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.159953\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.021206\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.010388\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.025428\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.012232\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.161971\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.004748\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.020124\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.270687\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.062326\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.122528\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.135669\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.102598\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.055469\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.150108\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.047156\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.070619\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.022552\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.215872\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.112535\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.108556\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.013672\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.107139\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.004878\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.005415\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.013512\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.144052\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.038532\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.109645\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.004466\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.054069\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.045014\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.046841\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.233348\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.002649\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.014517\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.002830\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.059400\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.033245\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.231096\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.037528\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.097255\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.284840\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.024025\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.110002\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.018957\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.039108\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.118435\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.078310\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.097316\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.084649\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.014627\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.025852\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.014065\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.157074\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.025079\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.014101\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.028370\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.045814\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.031093\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.019552\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.021332\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.034712\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.083337\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.001053\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.033735\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.171073\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.151646\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.090995\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.148441\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.018332\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.237635\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.005084\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.011892\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.084845\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.009203\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.038342\n",
      "\n",
      "Test set: Average loss: 0.0321, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.065815\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.012651\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.185637\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.041233\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.016024\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.094885\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.024814\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.019291\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.036736\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.049381\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.001176\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.128501\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.008107\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.017007\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.092803\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.022002\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.034954\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.024103\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.026977\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.113543\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.168536\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.081968\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.045907\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.009534\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.003609\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.074103\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.004881\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.024623\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.043440\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.031880\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.001205\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.020127\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.096521\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.009215\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.017932\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.018506\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.016943\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.038166\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.004867\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.041886\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.042821\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.102979\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.005460\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.315687\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.027620\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.024013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.014514\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.090279\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.188149\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.004411\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.033390\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.010528\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.048534\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.010191\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.025861\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.060293\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.020230\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.054875\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.047182\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.038594\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.057315\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.080829\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.004830\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.026829\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.024413\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.011385\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.004920\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.053821\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.023800\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.025736\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.014702\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.006530\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.089182\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.002441\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.052676\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.023534\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.006001\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.018246\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.063436\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.004512\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.003876\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.007045\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.043795\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.031060\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.004253\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.076229\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.002236\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.003382\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.014449\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.010831\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.013262\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.007056\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.029797\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.031752\n",
      "\n",
      "Test set: Average loss: 0.0336, Accuracy: 9897/10000 (98.97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.018277\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.024547\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.013075\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.007249\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.008612\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.100571\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.032057\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.021244\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.009037\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.041365\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.006268\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.001894\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.012839\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.014143\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.038095\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.007892\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.004269\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.009232\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.080063\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.062685\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.012719\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.096236\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.008319\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.019709\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.068721\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.035044\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.043158\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.046988\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.033016\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.021217\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.006744\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.034473\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.057360\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.017492\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.094821\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.040660\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.093874\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.070443\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.062591\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.017816\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.022404\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.065855\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.134425\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.153007\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.096783\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.008016\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.026951\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.036713\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.009108\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.071295\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.185780\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.007559\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.044926\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.008173\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.041611\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.044844\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.005307\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.006728\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.014169\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.020460\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.009157\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.003825\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.013796\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.062353\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.011954\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.001741\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.018652\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.023484\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.136051\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.004242\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.098661\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.013941\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.021540\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.018023\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.004139\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.075206\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.106331\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.039883\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.063059\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.008829\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.034605\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.003377\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.019039\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.062151\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.005970\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.025500\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.008458\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.005959\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.002716\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.016312\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.005765\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.021893\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.003504\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.004138\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 9915/10000 (99.15%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.085396\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.014832\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.195815\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.320501\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.058663\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.070311\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.023579\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.020443\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.000707\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.036966\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.022347\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.004627\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.005773\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.072745\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.096283\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.011587\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.006709\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.002825\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.005753\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.002255\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.087505\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.077531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.035587\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.005654\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.018508\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.009938\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.002046\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.000805\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.039715\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.052676\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.030487\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.003474\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.064585\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.006946\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.052987\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.002850\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.023933\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.043388\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.007222\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.001470\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.014468\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.066379\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.012519\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.014146\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.011426\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.027643\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.039165\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.179763\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.012103\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.026114\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.015085\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.152037\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.002848\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.004554\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.017184\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.065810\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.007493\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.026967\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.005532\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.002115\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.004723\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.030861\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.075433\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.016727\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.005893\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.091870\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.031474\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.033035\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.074091\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.039041\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.002821\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.029327\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.175976\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.076100\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.052319\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.013153\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.023383\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.087446\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.022305\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.030828\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.040028\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.004801\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.002856\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.029706\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.081848\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.097910\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.006788\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.076935\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.009115\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.010925\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.008381\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.009700\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.005102\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.003747\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 9915/10000 (99.15%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.019632\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.219739\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.002771\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.027015\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.053997\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.122812\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.050121\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.005579\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.065073\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.051872\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.012223\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.018469\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.005698\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.048225\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.002126\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.003024\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.009632\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.004444\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.036604\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.071258\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.021944\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.004853\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.057047\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.042323\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.001813\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.002970\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.005302\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.005915\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.269838\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.002329\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.016794\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.004562\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.039244\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.009479\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.064945\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.012118\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.033614\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.064130\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.010605\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.004467\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.057414\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.069784\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.008562\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.003487\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.015412\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.017928\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.002964\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.085736\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.007774\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.013505\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.006818\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.063840\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.008748\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.006910\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.000607\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.004609\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.007163\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.001021\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.003118\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.072317\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.057017\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.058509\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.067870\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.011307\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.003847\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.002284\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.002626\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.058658\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.111384\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.035999\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.006608\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.063301\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.005691\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.078419\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.031945\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.006432\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.056374\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.073737\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.004962\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.002088\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.014162\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.005345\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.017484\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.000401\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.000814\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.004893\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.020783\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.019681\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.008052\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.000710\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.010909\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.001641\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.066022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.107440\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 9915/10000 (99.15%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.009659\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.002220\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.000944\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.003012\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.022892\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.023546\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.021953\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.020801\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.000727\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.033981\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.028185\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.084916\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.003206\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.028293\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.005163\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.001793\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.061310\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.023638\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.001963\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.002000\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.028262\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.006702\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.036339\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.015796\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.018771\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.006158\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.002769\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.010509\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.002392\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.014060\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.101307\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.005876\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.005575\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.006962\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.005500\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.021537\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.001787\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.005713\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.148154\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.040047\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.004668\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.053540\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.136279\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.083124\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.014804\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.014393\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.079107\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.070095\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.027661\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.014260\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.001232\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.009266\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.005784\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.110666\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.003770\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.017421\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.014255\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.003108\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.026239\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.002657\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000652\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.001508\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.180259\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.019886\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.073911\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.010646\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.222169\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.014646\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.000642\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.062661\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.000755\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.105445\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.031545\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.032552\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.028120\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.020576\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.009272\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.043801\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.001477\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.003474\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.017911\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.018966\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.005588\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.139731\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.131340\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.030480\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.020719\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.007139\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.010285\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.003131\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.006469\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.017225\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.012925\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.015028\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 9913/10000 (99.13%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.002795\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.010541\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.015629\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.027999\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.003473\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.000537\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.019650\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.013001\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.002645\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.027011\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.062319\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.044064\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.070839\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.000997\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.013327\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.091906\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.030271\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.019686\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.008268\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.024465\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.037838\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.031004\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.036844\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.010975\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.027533\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.011841\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.038275\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.020375\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.039326\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.094743\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.027358\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.230551\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.002270\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.095121\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.003134\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.000811\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.033260\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.022791\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.058332\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.064302\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.016488\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.018305\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.001681\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.055695\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.003300\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.024863\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.064618\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.045229\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.002541\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.003521\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.002635\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.014598\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.071897\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.006488\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.003152\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.020173\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.057063\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.009743\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.014890\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.004457\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.049089\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.003822\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.001232\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.114473\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.002142\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.003711\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.014811\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.059810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.001732\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.009048\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.003021\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.112819\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.018566\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.002945\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.002099\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.005464\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.003171\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.007744\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.127336\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.183646\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.045202\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.047849\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.001665\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.114547\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.010136\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.024781\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.001775\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.001844\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.010938\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.001073\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.046102\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.009175\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.006974\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.005652\n",
      "\n",
      "Test set: Average loss: 0.0285, Accuracy: 9912/10000 (99.12%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.133446\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.002571\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.081173\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.025590\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.016293\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.006796\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.008924\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.014933\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.003828\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.013682\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.076299\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.004973\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.020683\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.008417\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.006285\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.087282\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.012156\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.011469\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.002167\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.006078\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.005883\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.038766\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.004408\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.000626\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.007895\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.000856\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.006491\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.017944\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.048927\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.027630\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.006343\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.001495\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.047403\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.009461\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.003992\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.054111\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.005898\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.030327\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.025355\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.015206\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.011929\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.001424\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.003452\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.001902\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.024266\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.022049\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.027334\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.077620\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.070202\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.004236\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.009390\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.005980\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.008107\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.001687\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.004196\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.001935\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.146999\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.095647\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.007275\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.003295\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.001042\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.001109\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.015330\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.011156\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.005196\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.044868\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.011448\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.023446\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.036461\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.000904\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.024368\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.033678\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.004881\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.048439\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.013067\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.000619\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.004135\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.001864\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.014358\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.011462\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.029390\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.021831\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.020227\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.137132\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.004318\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.004124\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.003114\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.054049\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.027704\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.000816\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.004932\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.003300\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.049310\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.013897\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 9919/10000 (99.19%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the optimizer and criterion for pre-training\n",
    "optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "\n",
    "# pre-train and evaluate the model on MNIST dataset\n",
    "total_epoch = 10\n",
    "\n",
    "for epoch in range(1, total_epoch+1):\n",
    "    train(model, device, optimizer=optimizer, epoch=epoch)\n",
    "    test(model, device)\n",
    "    scheduler.step()\n",
    "    \n",
    "torch.save(model, \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4435816",
   "metadata": {},
   "source": [
    "### Performance and statistics of original model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65e18e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 9919/10000 (99.19%)\n",
      "\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+----------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs   | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+----------+---------+\n",
      "|   0   | conv1 | Conv2d | (32, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 32, 26, 26) |  194688  |   320   |\n",
      "|   1   | conv2 | Conv2d | (64, 32, 3, 3) | (3, 32, 26, 26) | (3, 64, 24, 24) | 10616832 |  18496  |\n",
      "|   2   | fc1   | Linear |  (128, 9216)   |    (3, 9216)    |     (3, 128)    | 1179648  | 1179776 |\n",
      "|   3   | fc2   | Linear |   (10, 128)    |     (3, 128)    |     (3, 10)     |   1280   |   1290  |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+----------+---------+\n",
      "FLOPs total: 11992448\n",
      "#Params total: 1199882\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, Test-time:  1.8854s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "pre_best_acc = test(model, device)\n",
    "pre_test_time = time.time() - start\n",
    "\n",
    "pre_flops, pre_params, _ = count_flops_params(model, torch.randn([3, 1, 28, 28]).to(device))\n",
    "print(f'Pretrained model FLOPs {pre_flops/1e6:.2f} M, #Params: {pre_params/1e6:.2f}M, Accuracy: {pre_best_acc: .2f}%, Test-time: {pre_test_time: .4f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba20bd",
   "metadata": {},
   "source": [
    "# Pruning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69ea7c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.compression.pytorch.pruning import L1NormPruner\n",
    "from nni.compression.pytorch.pruning import L2NormPruner\n",
    "from nni.compression.pytorch.pruning import FPGMPruner\n",
    "from nni.compression.pytorch.speedup import ModelSpeedup\n",
    "\n",
    "def pruner_function(sparsity_per_layer, pruner_model):\n",
    "    config_list = [{\n",
    "        'sparsity_per_layer': sparsity_per_layer,\n",
    "        'op_types': ['Linear', 'Conv2d']\n",
    "    }, {\n",
    "        'exclude': True,\n",
    "        'op_names': ['fc2']\n",
    "    }]\n",
    "\n",
    "    model = torch.load(\"mnist_cnn.pt\")\n",
    "    model.eval()\n",
    "\n",
    "    # Using L1NormPruner to prune the model and generate the masks.\n",
    "    pruner = pruner_model(model, config_list)\n",
    "\n",
    "    # show the wrapped model structure, `PrunerModuleWrapper` have wrapped the layers that configured in the config_list.\n",
    "    #print(model)\n",
    "\n",
    "    # compress the model and generate the masks\n",
    "    _, masks = pruner.compress()\n",
    "\n",
    "    # show the masks sparsity\n",
    "    print(\"Showing the masks sparsity\")\n",
    "    for name, mask in masks.items():\n",
    "        print(name, ' sparsity : ', '{:.2}'.format(mask['weight'].sum() / mask['weight'].numel()))\n",
    "\n",
    "\n",
    "    # need to unwrap the model, if the model is wrapped before speedup\n",
    "    pruner._unwrap_model()\n",
    "\n",
    "    # speedup the model, for more information about speedup, please refer :doc:`pruning_speedup`.\n",
    "    ModelSpeedup(model, torch.rand(3, 1, 28, 28).to(device), masks).speedup_model()\n",
    "\n",
    "    #print(\"Model after speedup\")\n",
    "    #print(model)\n",
    "\n",
    "\n",
    "    # fine- tuning model compacted model\n",
    "    # tuning and evaluate the model on MNIST dataset\n",
    "    total_epoch = 3\n",
    "\n",
    "    optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "    \n",
    "    for epoch in range(1, total_epoch + 1):\n",
    "        train(model, device, optimizer=optimizer, epoch=epoch)\n",
    "        test(model, device)\n",
    "        scheduler.step()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53bb83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perfomance_function(model):\n",
    "    print(\"Model after speedup\")\n",
    "    print(model)\n",
    "    \n",
    "    start = time.time()\n",
    "    best_acc = test(model, device)\n",
    "    test_time = time.time() - start\n",
    "\n",
    "    flops, params, _ = count_flops_params(model, torch.randn([3, 1, 28, 28]).to(device))\n",
    "\n",
    "    print(f'Pretrained model FLOPs {pre_flops/1e6:.2f} M, #Params: {pre_params/1e6:.2f}M, Accuracy: {pre_best_acc: .2f}%, , Test-time: {pre_test_time: .4f}s')\n",
    "    print(f'Finetuned model FLOPs {flops/1e6:.2f} M, #Params: {params/1e6:.2f}M, Accuracy: {best_acc: .2f}%, Test-time: {test_time: .4f}s, Speed-up: {pre_test_time/test_time: .2f}x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1029e382",
   "metadata": {},
   "source": [
    "## L1 Norm Pruner (Config-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a50b59d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.91\n",
      "conv2  sparsity :  0.91\n",
      "fc1  sparsity :  0.91\n",
      "[2022-10-02 16:27:35] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mreplace linear with new in_features: 8352, out_features: 116\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mreplace linear with new in_features: 116, out_features: 10\u001b[0m\n",
      "[2022-10-02 16:27:35] \u001b[32mspeedup done\u001b[0m\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.023500\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.096424\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.079521\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.046456\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.141371\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.055091\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.137461\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.085891\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.018339\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.044138\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.012232\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.007546\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.108128\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.010121\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.000107\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.011926\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.050442\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.007348\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.112637\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.057635\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.006888\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.043066\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.078305\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.001728\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.044072\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.015269\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.041640\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.019534\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.109637\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.040107\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.084645\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.075083\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.034358\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.009539\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.278109\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.039559\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.005881\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.020190\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.024411\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.040550\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.004163\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.155727\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.077645\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.004736\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.055177\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.086707\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.001673\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.008502\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.001685\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.026363\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.100299\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.419152\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.031707\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.129729\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.133009\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.106339\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.009956\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.169396\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.000898\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.022659\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.027647\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.008847\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.019919\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.001939\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.096429\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.003730\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.020035\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.001995\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.019096\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.009234\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.019093\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.015306\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.003274\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.062751\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.059204\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.059703\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.030647\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.085653\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.072514\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.008742\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.006273\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.010517\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.259560\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.101547\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.195490\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.075329\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.007641\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.101554\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.164953\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.042328\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.149058\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.022004\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.007987\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.045484\n",
      "\n",
      "Test set: Average loss: 0.0494, Accuracy: 9851/10000 (98.51%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.119763\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.045085\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.004223\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.093829\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.040946\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.139878\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.007910\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.000860\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.092200\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.048601\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.075895\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.018369\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.087461\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.017962\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.041191\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.028423\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.071828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.009508\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.002385\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.097441\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.039617\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.039619\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.009359\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.113968\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.049102\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.000936\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.006014\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.112921\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.027854\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.011378\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.016386\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.003007\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.024569\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.010758\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.003347\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.082627\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.049076\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.035628\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.135967\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.053502\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.041109\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.029152\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.083652\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.045459\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.025142\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.054281\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.006372\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.048368\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.021625\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.001110\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.036647\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.071774\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.034397\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.022949\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.043077\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.024269\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.028068\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.078013\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.001266\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.000020\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.053676\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.023941\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.045127\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.006241\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.083224\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.056015\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.019912\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.031536\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.011748\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.017649\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.034406\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.004520\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.011027\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.001384\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.035963\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.001232\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.072034\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.009043\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.051716\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.044788\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.022636\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.024814\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.058362\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.001226\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.005162\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.022931\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.022039\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.005236\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.031051\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.004978\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.013233\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.017134\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.012735\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.016218\n",
      "\n",
      "Test set: Average loss: 0.0357, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.041222\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.006396\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.033017\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.006187\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.023324\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.021766\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.016001\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.204323\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.014936\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.000623\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.091032\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.147019\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.010655\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.047173\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.002804\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.005546\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.017676\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.001693\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.022172\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.001114\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.052252\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.009794\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.003696\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.003712\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.003392\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.029314\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.001270\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.001876\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.021527\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.001740\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.004700\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.000235\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.004719\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.002073\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.013569\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.044059\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.003708\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.102093\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.107218\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.004350\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.044892\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.099399\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.019834\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.007392\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.135187\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.059803\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.003821\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.004230\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.025155\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.001764\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.004691\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.043393\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.097387\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.047960\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.014508\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.000635\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.003222\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.112633\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.013005\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.044038\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.021978\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.003948\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.003227\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.013583\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.081222\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.003703\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.067319\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.061330\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.121038\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.062676\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.018011\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.024029\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.099644\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.117595\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.088175\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.012992\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.052339\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.089633\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.006683\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.031657\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.071902\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.099746\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.003859\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.011949\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.029882\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.026363\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.141345\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.007428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.006670\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.025595\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.053286\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.008073\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.095516\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.013780\n",
      "\n",
      "Test set: Average loss: 0.0305, Accuracy: 9909/10000 (99.09%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.10, pruner_model=L1NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd5dc068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 29, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(29, 58, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=8352, out_features=116, bias=True)\n",
      "  (fc2): Linear(in_features=116, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0305, Accuracy: 9909/10000 (99.09%)\n",
      "\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (29, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 29, 26, 26) |  176436 |   290   |\n",
      "|   1   | conv2 | Conv2d | (58, 29, 3, 3) | (3, 29, 26, 26) | (3, 58, 24, 24) | 8719488 |  15196  |\n",
      "|   2   | fc1   | Linear |  (116, 8352)   |    (3, 8352)    |     (3, 116)    |  968832 |  968948 |\n",
      "|   3   | fc2   | Linear |   (10, 116)    |     (3, 116)    |     (3, 10)     |   1160  |   1170  |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 9865916\n",
      "#Params total: 985604\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, , Test-time:  1.8854s\n",
      "Finetuned model FLOPs 9.87 M, #Params: 0.99M, Accuracy:  99.09%, Test-time:  1.8176s, Speed-up:  1.04x\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7ad48e",
   "metadata": {},
   "source": [
    "## L1 Norm Pruner (Config-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e99fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.75\n",
      "conv2  sparsity :  0.75\n",
      "fc1  sparsity :  0.75\n",
      "[2022-10-02 16:28:23] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mreplace linear with new in_features: 6912, out_features: 96\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mreplace linear with new in_features: 96, out_features: 10\u001b[0m\n",
      "[2022-10-02 16:28:23] \u001b[32mspeedup done\u001b[0m\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.014995\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.288725\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.038354\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.028022\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.010806\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.212082\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.092070\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.001166\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.054401\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.053909\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.154092\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.045055\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.089642\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.049002\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.027521\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.252211\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.056139\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.011895\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.023136\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.091789\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.166825\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.020405\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.060240\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.057077\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.076582\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.017112\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.028667\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.007998\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.008102\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.009831\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.003166\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.004060\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.051062\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.041677\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.020726\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.084268\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.044215\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.005030\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.099814\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.008714\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.041408\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.064421\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.049506\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.057201\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.015683\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.025866\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.094602\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.026256\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.225089\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.105654\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.010149\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.012240\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.016189\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.039397\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.005777\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.209551\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.081237\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.058227\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.066231\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.040995\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.119543\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.003504\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.054444\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.006671\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.020935\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.067027\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.003810\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.006054\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.049049\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.006551\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.064749\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.068502\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.200326\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.038086\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.062247\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.087111\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.096964\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.122269\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.018966\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.039264\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.020751\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.031550\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.096973\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.004270\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.049603\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.120817\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.075933\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.015026\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.034555\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.038945\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.060559\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.010855\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.052822\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.103062\n",
      "\n",
      "Test set: Average loss: 0.0352, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.029234\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.009945\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.020663\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.101627\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.126963\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.022562\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.148266\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.001075\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.153356\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.001944\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.000982\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.039039\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.024896\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.001892\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.017414\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.004600\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.057936\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.005310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.042785\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.011834\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.141987\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.006637\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.019988\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.107886\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.108486\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.034207\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.014253\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.002150\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.016180\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.027332\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.008505\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.021602\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.012026\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.002117\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.041358\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.107978\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.004974\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.022189\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.018943\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.007768\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.041646\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.117660\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.003576\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.064558\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.055588\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.224406\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.000728\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.001458\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.133549\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.009948\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.048349\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.001705\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.024123\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.048473\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.015079\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.050034\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.125773\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.004981\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.024530\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.101064\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.003395\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.000998\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.126348\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.091880\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.021566\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.117515\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.008172\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.041552\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.022129\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.038269\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.010988\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.002328\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.006646\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.068490\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.018224\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.005112\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.011164\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.015189\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.010681\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.123756\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.050678\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.012239\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.000377\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.096337\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.041650\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.032513\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.002971\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.014416\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.127276\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.050076\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.028800\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.034973\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.054098\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.004327\n",
      "\n",
      "Test set: Average loss: 0.0291, Accuracy: 9908/10000 (99.08%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.011399\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.012825\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.029058\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.002573\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.082715\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.055893\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.004631\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.009855\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.100131\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.036476\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.012693\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.195840\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.081590\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.014778\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.002949\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.004837\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.082182\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.001692\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.035614\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.004065\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.024137\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.002414\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.002764\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.034577\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.041777\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.012231\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.024208\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.092727\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.004726\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.004170\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.033914\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.008193\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.013136\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.038646\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.002854\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.024210\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.045912\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.004929\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.073618\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.013673\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.027344\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.064602\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.019065\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.011022\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.049166\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.083237\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.090508\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.032826\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.026569\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.045438\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.006237\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.098326\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.001734\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.141640\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.057491\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.001559\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.002695\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.164133\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.017707\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.067358\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.017409\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.023669\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.038000\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.032190\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.045870\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.001640\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.004817\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.010905\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.006225\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.066692\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.000056\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.000457\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.002127\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.003439\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.022301\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.001617\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.008200\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.027094\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.110692\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.065210\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.041746\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.020085\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.003579\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.036750\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.185926\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.055470\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.007000\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.137963\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.003810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.035156\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.011920\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.016896\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.067778\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.027381\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 9913/10000 (99.13%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.25, pruner_model=L1NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21ac7aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 24, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=6912, out_features=96, bias=True)\n",
      "  (fc2): Linear(in_features=96, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 9913/10000 (99.13%)\n",
      "\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (24, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 24, 26, 26) |  146016 |   240   |\n",
      "|   1   | conv2 | Conv2d | (48, 24, 3, 3) | (3, 24, 26, 26) | (3, 48, 24, 24) | 5971968 |  10416  |\n",
      "|   2   | fc1   | Linear |   (96, 6912)   |    (3, 6912)    |     (3, 96)     |  663552 |  663648 |\n",
      "|   3   | fc2   | Linear |    (10, 96)    |     (3, 96)     |     (3, 10)     |   960   |   970   |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 6782496\n",
      "#Params total: 675274\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, , Test-time:  1.8854s\n",
      "Finetuned model FLOPs 6.78 M, #Params: 0.68M, Accuracy:  99.13%, Test-time:  1.8779s, Speed-up:  1.00x\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e81cb",
   "metadata": {},
   "source": [
    "## L1 Norm Pruner (Config-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8724439c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.5\n",
      "conv2  sparsity :  0.5\n",
      "fc1  sparsity :  0.5\n",
      "[2022-10-02 16:29:08] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mreplace linear with new in_features: 4608, out_features: 64\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mreplace linear with new in_features: 64, out_features: 10\u001b[0m\n",
      "[2022-10-02 16:29:08] \u001b[32mspeedup done\u001b[0m\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.991826\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.081115\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.031613\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.030588\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.057768\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.158985\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.100000\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.162862\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.082551\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.034139\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.187043\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.111258\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.033154\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.137729\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.112332\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.075139\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.123541\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.253645\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.037848\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.079319\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.189417\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.220374\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.044110\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.099033\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.031569\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.097079\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.038221\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.076544\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.146834\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.190180\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.178411\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.094504\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.188271\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.038569\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.056673\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.066928\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.038532\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.081146\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.192774\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.125554\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.032863\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.041492\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.093938\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.074950\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.329697\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.062886\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.173863\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.068106\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.079623\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.029763\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.074210\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.167311\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.023688\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.042773\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.308959\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.045839\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.159302\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.047863\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.017047\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.146866\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.084439\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.137693\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.079278\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.096111\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.067743\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.157402\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.036984\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.023491\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.061716\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.038116\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.047415\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.015325\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.184638\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.012150\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.046475\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.105949\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.102710\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.139435\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.033262\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.007014\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.014514\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.127202\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.052341\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.090154\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.064053\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.178639\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.157070\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.298548\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.056991\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.104068\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.048040\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.072738\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.056246\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.244142\n",
      "\n",
      "Test set: Average loss: 0.0390, Accuracy: 9878/10000 (98.78%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.046152\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.075008\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.012580\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.010729\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.168053\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.047150\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.043825\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.015998\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.086670\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.095932\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.003238\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.014088\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.029103\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.021260\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.010681\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.059051\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.052400\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.004850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.036789\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.010728\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.008305\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.053743\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.049573\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.136417\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.036306\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.172122\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.105192\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.081989\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.033444\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.017688\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.033093\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.097685\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.080538\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.149903\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.046932\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.042544\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.052187\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.013083\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.055032\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.135576\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.028594\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.024525\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.160325\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.006442\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.006163\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.010345\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.053434\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.129438\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.062407\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.070513\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.113987\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.038670\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.017980\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.017005\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.036058\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.052660\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.051690\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.021317\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.027545\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.094803\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.336067\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.069841\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.022248\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.227654\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.108504\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.014652\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.082979\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.129635\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.047025\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.084943\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.003378\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.044051\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.112970\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.010370\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.005403\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.168372\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.075491\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.008599\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.046814\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.074505\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.018180\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.020671\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.088546\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.057936\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.041828\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.163713\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.142344\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.027736\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.130442\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.070971\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.007054\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.017695\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.076366\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.139018\n",
      "\n",
      "Test set: Average loss: 0.0354, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.114242\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.072316\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.078123\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.022846\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.005975\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.051530\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.070284\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.024919\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.033032\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.121121\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.038580\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.013894\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.011521\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.108382\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.009237\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.266706\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.056506\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.014625\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.001507\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.189885\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.017843\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.068844\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.058528\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.154447\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.180957\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.121382\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.039403\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.003161\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.088312\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.004621\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.072639\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.020036\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.032451\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.073713\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.021515\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.040465\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.041244\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.043808\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.051373\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.023536\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.023703\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.018117\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.007508\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.074082\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.055268\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.013135\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.060465\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.017030\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.116960\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.044885\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.024596\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.033036\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.067639\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.121422\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.015208\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.161890\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.172703\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.123248\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.012576\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.050158\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.062077\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.034903\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.015695\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.026672\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.106991\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.002826\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.047878\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.020695\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.041844\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.063579\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.007596\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.125823\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.010528\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.040753\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.003424\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.018959\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.191140\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.084810\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.009499\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.065766\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.153856\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.085587\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.028979\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.080335\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.022827\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.030080\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.028030\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.048995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.114670\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.128785\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.027181\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.087899\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.125673\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.007319\n",
      "\n",
      "Test set: Average loss: 0.0342, Accuracy: 9894/10000 (98.94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.50, pruner_model=L1NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c696ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=4608, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0342, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (16, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 16, 26, 26) |  97344  |   160   |\n",
      "|   1   | conv2 | Conv2d | (32, 16, 3, 3) | (3, 16, 26, 26) | (3, 32, 24, 24) | 2654208 |   4640  |\n",
      "|   2   | fc1   | Linear |   (64, 4608)   |    (3, 4608)    |     (3, 64)     |  294912 |  294976 |\n",
      "|   3   | fc2   | Linear |    (10, 64)    |     (3, 64)     |     (3, 10)     |   640   |   650   |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 3047104\n",
      "#Params total: 300426\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, , Test-time:  1.8854s\n",
      "Finetuned model FLOPs 3.05 M, #Params: 0.30M, Accuracy:  98.94%, Test-time:  1.5542s, Speed-up:  1.21x\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223df22",
   "metadata": {},
   "source": [
    "## L1 Norm Pruner (Config-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db5ba44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.25\n",
      "conv2  sparsity :  0.25\n",
      "fc1  sparsity :  0.25\n",
      "[2022-10-02 16:29:48] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mreplace linear with new in_features: 2304, out_features: 32\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mreplace linear with new in_features: 32, out_features: 10\u001b[0m\n",
      "[2022-10-02 16:29:48] \u001b[32mspeedup done\u001b[0m\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.966932\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.660259\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.381414\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.456493\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.366366\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.278499\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.454350\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.262504\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.396080\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.282859\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.455394\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.266305\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.240959\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.329496\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.169378\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.173664\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.286105\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.265165\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.366214\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.204515\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.216865\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.295168\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.173680\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.242290\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.274930\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.117792\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.368414\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.261708\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.145484\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.204655\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.226590\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.261960\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.262162\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.255529\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.237283\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.198998\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.238374\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.154820\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.153214\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.259612\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.139409\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.182457\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.214922\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.198220\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.549344\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.275138\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.215250\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.228813\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.304153\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.212985\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.225911\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.217134\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.298818\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.195491\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.121758\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.216806\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.188540\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.120899\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.260705\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.168095\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.276585\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.189053\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.155273\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.168344\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.259261\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.103988\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.207521\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.435595\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.124808\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.163556\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.259678\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.184376\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.200769\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.184271\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.171879\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.137715\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.084199\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.326630\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.250313\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.254335\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.169273\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.383981\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.278302\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.163533\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.071035\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.081355\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.146701\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.304808\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.314400\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.225113\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.397311\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.134658\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.234450\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.122793\n",
      "\n",
      "Test set: Average loss: 0.0557, Accuracy: 9831/10000 (98.31%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.075543\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.190192\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.110846\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.099811\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.266064\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.114600\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.063413\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.172075\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.078323\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.088286\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.245439\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.131361\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.133239\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.174806\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.126869\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.298741\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.129596\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.155338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.166557\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.298618\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.186228\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.187268\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.150712\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.420571\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.199168\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.322706\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.263146\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.337210\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.280900\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.141729\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.154941\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.407701\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.089627\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.126263\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.074486\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.111531\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.091693\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.256617\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.278091\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.176237\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.091185\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.096407\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.121506\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.043111\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.287990\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.073195\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.159187\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.099518\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.265669\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.206138\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.137161\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.211774\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.195220\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.179543\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.131172\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.232408\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.093620\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.256854\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.348209\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.147224\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.216810\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.199724\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.116280\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.285232\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.096021\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.209128\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.056994\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.107360\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.113538\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.191011\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.239324\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.164773\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.128735\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.224316\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.226588\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.191109\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.252344\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.179170\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.275850\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.247041\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.180007\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.176783\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.319397\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.249209\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.117874\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.122048\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.133774\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.065025\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.130195\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.076580\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.143666\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.151507\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.191546\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.058506\n",
      "\n",
      "Test set: Average loss: 0.0510, Accuracy: 9860/10000 (98.60%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.107037\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.073274\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.136452\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.146432\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.187902\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.086777\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.264890\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.143953\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.042435\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.105814\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.045192\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.067712\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.018260\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.106785\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.437739\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.197514\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.183830\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.215916\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.134203\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.043318\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.228272\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.068921\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.216851\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.412392\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.101005\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.066821\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.081346\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.276787\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.074784\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.104786\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.074789\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.129922\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.170326\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.116141\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.039641\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.357944\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.164624\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.087578\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.192729\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.208933\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.191152\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.153987\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.197450\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.184036\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.063288\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.242981\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.204938\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.102227\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.177772\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.111819\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.105654\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.060354\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.107489\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.166451\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.145475\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.121245\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.115537\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.431275\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.263002\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.229072\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.127741\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.150720\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.115294\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.245300\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.127062\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.123957\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.134754\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.084295\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.053366\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.121139\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.243085\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.270320\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.066045\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.463359\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.108695\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.102477\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.174625\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.082646\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.179688\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.056904\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.166853\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.153920\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.113570\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.131992\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.197044\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.084804\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.099299\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.142289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.079915\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.096151\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.208797\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.175792\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.341057\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.170929\n",
      "\n",
      "Test set: Average loss: 0.0497, Accuracy: 9855/10000 (98.55%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.75, pruner_model=L1NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60f3aa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=2304, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0497, Accuracy: 9855/10000 (98.55%)\n",
      "\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape |   Input Size   |   Output Size   | FLOPs  | #Params |\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "|   0   | conv1 | Conv2d |  (8, 1, 3, 3) | (3, 1, 28, 28) |  (3, 8, 26, 26) | 48672  |    80   |\n",
      "|   1   | conv2 | Conv2d | (16, 8, 3, 3) | (3, 8, 26, 26) | (3, 16, 24, 24) | 663552 |   1168  |\n",
      "|   2   | fc1   | Linear |   (32, 2304)  |   (3, 2304)    |     (3, 32)     | 73728  |  73760  |\n",
      "|   3   | fc2   | Linear |    (10, 32)   |    (3, 32)     |     (3, 10)     |  320   |   330   |\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "FLOPs total: 786272\n",
      "#Params total: 75338\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, , Test-time:  1.8854s\n",
      "Finetuned model FLOPs 0.79 M, #Params: 0.08M, Accuracy:  98.55%, Test-time:  1.6341s, Speed-up:  1.15x\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe045aec",
   "metadata": {},
   "source": [
    "## L2 Norm Pruner (Config 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "810c999b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.91\n",
      "conv2  sparsity :  0.91\n",
      "fc1  sparsity :  0.91\n",
      "[2022-10-02 16:30:31] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mreplace linear with new in_features: 8352, out_features: 116\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mreplace linear with new in_features: 116, out_features: 10\u001b[0m\n",
      "[2022-10-02 16:30:31] \u001b[32mspeedup done\u001b[0m\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.058083\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.003630\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.131371\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.063804\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.145141\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.111243\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.038561\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.051902\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.015209\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.038271\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.004337\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.110500\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.066879\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.005326\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.018950\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.010030\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.017255\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.022000\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.000906\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.011135\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.038386\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.119911\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.050246\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.018058\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.086259\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.036146\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.055677\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.071109\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.011774\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.123219\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.259934\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.008121\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.144429\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.097742\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.001484\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.026847\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.056400\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.094397\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.006541\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.218108\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.038246\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.083927\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.005545\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.064679\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.040373\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.080357\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.050780\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.013839\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.008086\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.058253\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.001685\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.002552\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.027448\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.014909\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.196378\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.048035\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.005809\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.038395\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.094370\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.025879\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.003720\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.181884\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.001288\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.042747\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.035237\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.111039\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.078604\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.029450\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.017199\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.032328\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.200266\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.080367\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.134288\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.016276\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.020767\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.057806\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.029167\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.051215\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.042953\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.011655\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.051314\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.022151\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.035239\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.034115\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.084913\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.105142\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.006642\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.062694\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.073780\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.031570\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.038985\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.010472\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.046802\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.152418\n",
      "\n",
      "Test set: Average loss: 0.0425, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.054790\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.019187\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.004947\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.064032\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.009424\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.005027\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.035671\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.018079\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.018579\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.007774\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.041607\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.013918\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.054286\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.001535\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.025054\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.025640\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.042810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.080050\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.186243\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.001195\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.073740\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.008313\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.000462\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.006761\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.129656\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.009249\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.039693\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.033451\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.106066\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.156754\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.050458\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.003188\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.038877\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.061359\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.031837\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.103284\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.103410\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.078299\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.069612\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.053228\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.014342\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.003947\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.013771\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.000618\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.143246\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.026214\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.022444\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.100766\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.107849\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.026486\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.016779\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.000478\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.070075\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.077111\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.037781\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.020762\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.014310\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.002236\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.029212\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.068638\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.045651\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.025375\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.009519\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.018661\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.155077\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.005795\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.028703\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.028682\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.188463\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.056561\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.069388\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.004550\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.023787\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.042558\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.004017\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.065039\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.001967\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.000694\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.135529\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.066238\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.153274\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.003031\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.002254\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.083240\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.064704\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.024807\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.026608\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.089842\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.012626\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.014549\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.020118\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.013720\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.005902\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.010859\n",
      "\n",
      "Test set: Average loss: 0.0335, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.001972\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.011824\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.002848\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.044671\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.001506\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.001301\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.010461\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.002033\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.048557\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.004109\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.003521\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.011473\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.083871\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.004499\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.051214\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.008466\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.007453\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.011528\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.040154\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.004503\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.055282\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.008552\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.006577\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.001649\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.002956\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.000307\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.069749\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.017962\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.007904\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.048181\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.080646\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.029149\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.056118\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.125789\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.010358\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.008181\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.104687\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.173873\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.012959\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.001934\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.013570\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.121456\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.005066\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.024127\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.097500\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.033007\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.165487\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.014106\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.007170\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.015528\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.009262\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.018816\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.001547\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.020183\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.004616\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.000493\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.000494\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.002940\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.167215\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.078759\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.010934\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.021752\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.050081\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.054480\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.105101\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.006934\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.021065\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.074372\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.001935\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.008040\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.007946\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.049185\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.054692\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.045246\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.010893\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.026714\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.017736\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.025290\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.001459\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.003157\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.000651\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.113077\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.042424\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.040576\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.009183\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.009797\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.030871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.079747\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.005153\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.001197\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.150520\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.016828\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.012304\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.113681\n",
      "\n",
      "Test set: Average loss: 0.0314, Accuracy: 9914/10000 (99.14%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.10, pruner_model=L2NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc530ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 29, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(29, 58, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=8352, out_features=116, bias=True)\n",
      "  (fc2): Linear(in_features=116, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0314, Accuracy: 9914/10000 (99.14%)\n",
      "\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (29, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 29, 26, 26) |  176436 |   290   |\n",
      "|   1   | conv2 | Conv2d | (58, 29, 3, 3) | (3, 29, 26, 26) | (3, 58, 24, 24) | 8719488 |  15196  |\n",
      "|   2   | fc1   | Linear |  (116, 8352)   |    (3, 8352)    |     (3, 116)    |  968832 |  968948 |\n",
      "|   3   | fc2   | Linear |   (10, 116)    |     (3, 116)    |     (3, 10)     |   1160  |   1170  |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 9865916\n",
      "#Params total: 985604\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, , Test-time:  1.8854s\n",
      "Finetuned model FLOPs 9.87 M, #Params: 0.99M, Accuracy:  99.14%, Test-time:  1.6913s, Speed-up:  1.11x\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b4ec86",
   "metadata": {},
   "source": [
    "## L2 Norm Pruner (Config 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd32919b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.75\n",
      "conv2  sparsity :  0.75\n",
      "fc1  sparsity :  0.75\n",
      "[2022-10-02 16:31:20] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mreplace linear with new in_features: 6912, out_features: 96\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mreplace linear with new in_features: 96, out_features: 10\u001b[0m\n",
      "[2022-10-02 16:31:20] \u001b[32mspeedup done\u001b[0m\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.024694\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.123163\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.021480\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.008026\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.011239\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.057620\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.046373\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.040646\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.031021\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.017255\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.041131\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.050594\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.038965\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.054667\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.006254\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.048560\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.006233\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.017449\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.065810\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.015020\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.088024\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.100773\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.067778\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.019135\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.058706\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.001600\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.027759\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.047527\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.136226\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.041053\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.057268\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.003807\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.070197\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.035086\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.060253\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.091637\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.100525\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.007153\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.052693\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.032216\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.022307\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.002204\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.004969\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.019052\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.063025\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.098033\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.050533\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.053307\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.188011\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.079109\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.085485\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.117681\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.082382\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.055167\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.034877\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.113406\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.010735\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.046422\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.022934\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.125236\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.011303\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.010821\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.037956\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.111331\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.037587\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.047285\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.004098\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.035562\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.071333\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.002845\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.005026\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.017003\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.055192\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.020257\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.016937\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.092819\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.044211\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.015401\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.049946\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.029160\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.053374\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.036504\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.015590\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.007481\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.025215\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.013591\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.056663\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.121850\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.035141\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.106250\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.013849\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.013469\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.041039\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.189926\n",
      "\n",
      "Test set: Average loss: 0.0341, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.012989\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.032765\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.023648\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.001767\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.005576\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.115876\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.043518\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.037816\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.040399\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.012838\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.107739\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.007383\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.010781\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.010067\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.053986\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.029306\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.029354\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.013666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.002552\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.000589\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.040155\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.006108\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.134721\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.002342\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.038675\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.021252\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.010372\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.071195\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.007027\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.002228\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.004176\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.051325\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.282347\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.020886\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.047656\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.179616\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.046658\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.052688\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.060635\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.072659\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.007607\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.058228\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.124066\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.051834\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.008110\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.001800\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.069201\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.078305\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.054206\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.177577\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.145238\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.019921\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.048329\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.012907\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.037997\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.026144\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.007437\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.073592\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.008903\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.115250\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.030876\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.037711\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.006582\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.014517\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.033543\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.299971\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.056609\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.043713\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.058436\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.011967\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.003979\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.010178\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.017682\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.098846\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.031750\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.002888\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.024196\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.150076\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.006227\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.126278\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.006031\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.042284\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.069854\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.004015\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.054246\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.030536\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.025104\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.024645\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.009928\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.001650\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.040496\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.044722\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.078660\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.030237\n",
      "\n",
      "Test set: Average loss: 0.0350, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.000712\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.088178\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.044021\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.160171\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.006932\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.103090\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.042440\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.119878\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.071518\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.118956\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.009232\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.037739\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.096973\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.017145\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.011988\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.064035\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.101082\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.015186\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.018903\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.031551\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.003441\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.002026\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.009934\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.028689\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.092787\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.050311\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.000468\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.028180\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.001147\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.001983\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.116059\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.032815\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.013332\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.048484\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.011898\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.074138\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.027443\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.084904\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.134036\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.127679\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.001180\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.015137\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.007591\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.059997\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.010657\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.009611\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.015227\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.019540\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.035937\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.008552\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.014841\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.008276\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.032257\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.001631\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.125166\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.002667\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.147778\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.019047\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.011216\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.005005\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.001241\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.112070\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.012144\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.126832\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.001527\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.001922\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.036153\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.001533\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.000758\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.095899\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.012432\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.029418\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.024186\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.005183\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.008768\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.027917\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.001239\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.130798\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.005780\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.006883\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.026698\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.110410\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.003844\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.076008\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.010138\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.103899\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.002822\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.048891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.056027\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.026597\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.093556\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.051354\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.010862\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.008169\n",
      "\n",
      "Test set: Average loss: 0.0331, Accuracy: 9898/10000 (98.98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.25, pruner_model=L2NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d5eb215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 24, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=6912, out_features=96, bias=True)\n",
      "  (fc2): Linear(in_features=96, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0331, Accuracy: 9898/10000 (98.98%)\n",
      "\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (24, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 24, 26, 26) |  146016 |   240   |\n",
      "|   1   | conv2 | Conv2d | (48, 24, 3, 3) | (3, 24, 26, 26) | (3, 48, 24, 24) | 5971968 |  10416  |\n",
      "|   2   | fc1   | Linear |   (96, 6912)   |    (3, 6912)    |     (3, 96)     |  663552 |  663648 |\n",
      "|   3   | fc2   | Linear |    (10, 96)    |     (3, 96)     |     (3, 10)     |   960   |   970   |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 6782496\n",
      "#Params total: 675274\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, , Test-time:  1.8854s\n",
      "Finetuned model FLOPs 6.78 M, #Params: 0.68M, Accuracy:  98.98%, Test-time:  1.8629s, Speed-up:  1.01x\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b5d54c",
   "metadata": {},
   "source": [
    "## L2 Norm Pruner (Config 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "300e93fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.5\n",
      "conv2  sparsity :  0.5\n",
      "fc1  sparsity :  0.5\n",
      "[2022-10-02 16:32:04] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mreplace linear with new in_features: 4608, out_features: 64\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mreplace linear with new in_features: 64, out_features: 10\u001b[0m\n",
      "[2022-10-02 16:32:04] \u001b[32mspeedup done\u001b[0m\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.429163\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.063159\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.091926\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.023962\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.123716\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.028001\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.061678\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.163417\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.352510\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.098632\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.055163\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.101962\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.086644\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.198447\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.140115\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.063330\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.012048\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.013305\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.150420\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.044546\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.188238\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.031409\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.093711\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.101556\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.085719\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.068654\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.202086\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.063277\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.029390\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.112469\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.030859\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.018139\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.079193\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.171803\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.068069\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.019228\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.114716\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.131338\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.051017\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.033907\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.085537\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.076446\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.323084\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.061592\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.148243\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.068638\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.051173\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.231717\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.121918\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.025044\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.130339\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.017734\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.114168\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.042693\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.082567\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.084947\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.102126\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.041861\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.047286\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.246725\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.042682\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.057413\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.145536\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.088373\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.060459\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.131633\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.051780\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.046986\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.067935\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.219120\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.043948\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.040379\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.101590\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.043652\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.042608\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.176490\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.023509\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.133535\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.101479\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.037118\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.045817\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.022828\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.091803\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.119656\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.066777\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.016898\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.150835\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.177783\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.008070\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.123600\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.061338\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.032531\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.180369\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.188510\n",
      "\n",
      "Test set: Average loss: 0.0478, Accuracy: 9852/10000 (98.52%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.116242\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.198029\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.269223\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.090384\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.181366\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.064783\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.030705\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.071636\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.021730\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.011171\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.187359\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.068920\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.073578\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.135085\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.110458\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.034064\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.037630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.109434\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.109571\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.066455\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.020495\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.039712\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.043419\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.110945\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.077504\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.048009\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.043612\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.166408\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.008872\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.094088\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.006569\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.008534\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.070549\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.025078\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.063980\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.084327\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.243283\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.054020\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.035754\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.056364\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.134225\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.062799\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.085528\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.046275\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.186064\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.020809\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.129178\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.081615\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.040168\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.063981\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.145973\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.051618\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.035173\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.069503\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.022707\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.098498\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.168891\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.067376\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.025975\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.043270\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.335647\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.012612\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.108802\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.035046\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.012129\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.021505\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.253482\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.028027\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.024507\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.014955\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.036744\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.076384\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.041276\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.030380\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.006873\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.097985\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.141075\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.006544\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.008868\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.016841\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.111656\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.042474\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.050773\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.048903\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.058631\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.139575\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.064541\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.126542\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.040153\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.043008\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.077718\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.113158\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.047591\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.043261\n",
      "\n",
      "Test set: Average loss: 0.0396, Accuracy: 9876/10000 (98.76%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.005507\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.073214\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.008696\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.133960\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.029159\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.025037\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.044687\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.142403\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.022239\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.040760\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.076590\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.060887\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.035743\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.032176\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.015222\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.001139\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.006136\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.077199\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.094565\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.017615\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.009393\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.067076\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.048808\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.020481\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.018706\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.029942\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.033990\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.090476\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.027980\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.111778\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.056961\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.161182\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.023740\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.092005\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.091317\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.029827\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.144689\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.058363\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.168800\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.214242\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.045553\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.098298\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.031597\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.494086\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.011959\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.109554\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.028546\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.006844\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.017645\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.269029\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.088372\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.234210\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.022200\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.003237\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.113013\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.034288\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.038710\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.014681\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.071456\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.063249\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.045115\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.063563\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.115068\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.016020\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.016579\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.062649\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.160612\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.055534\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.071416\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.006210\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.063350\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.030517\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.003740\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.027535\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.029970\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.092198\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.007965\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.025164\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.037147\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.092538\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.061038\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.063353\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.050234\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.040423\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.064102\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.039729\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.031100\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.003905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.045505\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.009518\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.063645\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.050575\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.007139\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.027582\n",
      "\n",
      "Test set: Average loss: 0.0361, Accuracy: 9884/10000 (98.84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.50, pruner_model=L2NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3ebb279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=4608, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0361, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (16, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 16, 26, 26) |  97344  |   160   |\n",
      "|   1   | conv2 | Conv2d | (32, 16, 3, 3) | (3, 16, 26, 26) | (3, 32, 24, 24) | 2654208 |   4640  |\n",
      "|   2   | fc1   | Linear |   (64, 4608)   |    (3, 4608)    |     (3, 64)     |  294912 |  294976 |\n",
      "|   3   | fc2   | Linear |    (10, 64)    |     (3, 64)     |     (3, 10)     |   640   |   650   |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 3047104\n",
      "#Params total: 300426\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, , Test-time:  1.8854s\n",
      "Finetuned model FLOPs 3.05 M, #Params: 0.30M, Accuracy:  98.84%, Test-time:  1.6921s, Speed-up:  1.11x\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c97fbc",
   "metadata": {},
   "source": [
    "## L2 Norm Pruner (Config-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f429c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.25\n",
      "conv2  sparsity :  0.25\n",
      "fc1  sparsity :  0.25\n",
      "[2022-10-02 16:32:45] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mreplace linear with new in_features: 2304, out_features: 32\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mreplace linear with new in_features: 32, out_features: 10\u001b[0m\n",
      "[2022-10-02 16:32:46] \u001b[32mspeedup done\u001b[0m\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.526625\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.632503\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.605771\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.277128\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.403971\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.368914\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.205866\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.406650\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.224613\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.306545\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.190892\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.247239\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.169839\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.237987\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.255788\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.401143\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.273237\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.201430\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.246677\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.137341\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.246185\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.093363\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.226995\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.267331\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.277951\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.197016\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.110356\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.528634\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.224824\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.244080\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.311033\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.118886\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.121116\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.195786\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.299356\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.296052\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.438359\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.130789\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.203150\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.208661\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.217214\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.356901\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.104827\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.089016\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.181809\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.218195\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.207472\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.325883\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.293492\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.438002\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.138794\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.233927\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.275335\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.219939\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.315437\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.383925\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.184048\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.245053\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.201496\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.114538\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.220203\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.311525\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.292588\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.188480\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.222075\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.202674\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.218259\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.234997\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.139031\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.247860\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.110079\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.182247\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.328566\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.128000\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.113928\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.331512\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.132947\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.233922\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.175518\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.319920\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.411714\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.057545\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.177139\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.339079\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.232295\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.242496\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.146716\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.189755\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.161033\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.174103\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.343153\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.229866\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.102787\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.271751\n",
      "\n",
      "Test set: Average loss: 0.0577, Accuracy: 9835/10000 (98.35%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.189938\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.105422\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.126759\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.237351\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.229857\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.177560\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.088892\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.145411\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.243654\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.250848\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.158963\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.184897\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.132349\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.080703\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.132949\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.142251\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.248613\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.089277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.184801\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.159894\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.166397\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.144231\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.092041\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.101836\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.084615\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.164311\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.153553\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.090125\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.081705\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.130468\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.314922\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.226980\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.183066\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.176140\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.252001\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.126385\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.137757\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.197119\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.097360\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.164953\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.102001\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.166447\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.177920\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.130729\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.143037\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.253442\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.356467\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.053269\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.099851\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.178931\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.130928\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.117077\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.285412\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.111307\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.433291\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.146784\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.258880\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.158703\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.300927\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.208085\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.229432\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.134439\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.111339\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.167600\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.138715\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.210091\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.190348\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.175086\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.115974\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.174262\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.103470\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.176420\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.245914\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.204227\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.206989\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.127912\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.164457\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.111677\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.319632\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.286598\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.315480\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.132731\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.194024\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.050010\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.063892\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.390932\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.484467\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.079905\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.235466\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.244015\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.116323\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.165580\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.143095\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.226303\n",
      "\n",
      "Test set: Average loss: 0.0522, Accuracy: 9838/10000 (98.38%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.072671\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.143692\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.616596\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.185518\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.189755\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.108872\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.302446\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.131267\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.110158\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.136255\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.222562\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.170500\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.094606\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.132582\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.112160\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.061574\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.105923\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.122842\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.090277\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.233745\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.132915\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.131749\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.303765\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.148096\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.085532\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.143629\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.196637\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.093654\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.074517\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.336779\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.214257\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.098435\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.338847\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.030077\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.126072\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.089524\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.390030\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.229836\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.161914\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.103651\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.249496\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.224429\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.105076\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.201179\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.238888\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.191112\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.386989\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.115183\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.225172\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.122779\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.116718\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.226677\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.209073\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.199717\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.244346\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.129639\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.218018\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.173980\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.198998\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.120454\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.114285\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.131713\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.041337\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.266061\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.166357\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.161100\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.158768\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.207102\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.155481\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.057054\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.055436\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.125631\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.132731\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.108464\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.086468\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.232926\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.285132\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.263937\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.129082\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.103803\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.097746\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.229069\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.071053\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.183314\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.118386\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.217889\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.236801\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.178722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.120181\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.045314\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.120767\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.081937\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.109291\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.056409\n",
      "\n",
      "Test set: Average loss: 0.0469, Accuracy: 9864/10000 (98.64%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.75, pruner_model=L2NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8beb1923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=2304, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0469, Accuracy: 9864/10000 (98.64%)\n",
      "\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape |   Input Size   |   Output Size   | FLOPs  | #Params |\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "|   0   | conv1 | Conv2d |  (8, 1, 3, 3) | (3, 1, 28, 28) |  (3, 8, 26, 26) | 48672  |    80   |\n",
      "|   1   | conv2 | Conv2d | (16, 8, 3, 3) | (3, 8, 26, 26) | (3, 16, 24, 24) | 663552 |   1168  |\n",
      "|   2   | fc1   | Linear |   (32, 2304)  |   (3, 2304)    |     (3, 32)     | 73728  |  73760  |\n",
      "|   3   | fc2   | Linear |    (10, 32)   |    (3, 32)     |     (3, 10)     |  320   |   330   |\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "FLOPs total: 786272\n",
      "#Params total: 75338\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, , Test-time:  1.8854s\n",
      "Finetuned model FLOPs 0.79 M, #Params: 0.08M, Accuracy:  98.64%, Test-time:  1.4421s, Speed-up:  1.31x\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe31032",
   "metadata": {},
   "source": [
    "## FPGM Pruner (Config-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "beac18dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.91\n",
      "conv2  sparsity :  0.91\n",
      "fc1  sparsity :  0.91\n",
      "[2022-10-02 16:33:27] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mreplace linear with new in_features: 8352, out_features: 116\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mreplace linear with new in_features: 116, out_features: 10\u001b[0m\n",
      "[2022-10-02 16:33:27] \u001b[32mspeedup done\u001b[0m\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.074244\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.059253\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.082174\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.037442\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.050311\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.184477\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.070859\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.077757\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.176046\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.140953\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.075199\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.005209\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.022296\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.013994\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.019695\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.007401\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.053356\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.025917\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.037835\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.118757\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.059751\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.003850\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.089699\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.046261\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.030108\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.153394\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.006650\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.024179\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.001085\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.044381\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.026649\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.394676\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.006752\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.001794\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.020536\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.020014\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.022901\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.003232\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.103035\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.149614\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.031922\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.056693\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.027014\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.123718\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.059152\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.007377\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.055337\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.040640\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.026049\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.022669\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.028664\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.025525\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.180902\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.104281\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.177458\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.034112\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.004579\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.059245\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.024173\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.014833\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.006916\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.006829\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.044869\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.015448\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.002166\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.086852\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.011791\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.001115\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.020112\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.193068\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.035810\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.051962\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.121585\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.054086\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.024889\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.037511\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.009376\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.067756\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.013211\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.128470\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.019570\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.062467\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.008640\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.101407\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.017714\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.017167\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.000246\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.055175\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.034194\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.049866\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.003294\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.027189\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.049309\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.063269\n",
      "\n",
      "Test set: Average loss: 0.0418, Accuracy: 9868/10000 (98.68%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.037623\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.039379\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.007827\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.019548\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.094973\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.103466\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.202108\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.058829\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.023036\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.011254\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.057950\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.038718\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.079182\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.002239\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.045483\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.081904\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.091262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.001939\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.025274\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.002008\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.038311\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.025527\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.001185\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.002014\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.016824\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.056083\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.042669\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.000780\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.100751\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.022105\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.100982\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.099091\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.085797\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.005038\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.016218\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.010421\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.001392\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.003515\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.000489\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.008400\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.001473\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.084889\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.081865\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.045832\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.207799\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.037151\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.010893\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.012277\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.010311\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.000611\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.004130\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.014082\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.015029\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.058465\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.011281\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.012406\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.010491\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.019552\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.009791\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.020108\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.004801\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.015263\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.045946\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.049959\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.028304\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.041456\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.017852\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.074842\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.001063\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.018429\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.074647\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.012149\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.003106\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.015890\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.004806\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.000520\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.000270\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.053176\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.060406\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.088752\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.075066\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.005303\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.062962\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.023107\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.006572\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.003371\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.099765\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.044297\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.013224\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.100746\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.011181\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.101525\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.047439\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.018130\n",
      "\n",
      "Test set: Average loss: 0.0315, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.002121\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.120579\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.083728\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.192822\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.018892\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.034849\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.033168\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.011019\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.007265\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.002539\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.005748\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.007748\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.012075\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.002265\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.004315\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.198629\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.015144\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.211024\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.012642\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.003861\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.000456\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.005951\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.049562\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.001817\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.156826\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.018582\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.032386\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.115399\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.000309\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.072492\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.016564\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.010077\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.037369\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.013317\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.000929\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.035311\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.050095\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.014353\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.024395\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.025508\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.219381\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.038073\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.050003\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.015618\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.010972\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.048863\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.031481\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.023747\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.268505\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.006965\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.004289\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.001493\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.014294\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.018003\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.000888\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.001144\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.016925\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.005115\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.004549\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.058003\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.075042\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.015153\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.102517\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.006847\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.007291\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.102284\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.084415\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.075879\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.018529\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.008679\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.003788\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.026497\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.006547\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.180316\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.003970\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.002489\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.008047\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.046667\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.000210\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.010155\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.157736\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.142770\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.195531\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.002138\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.236289\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.036439\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.000059\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.008638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.012660\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.001898\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.041995\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.001115\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.006497\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.001775\n",
      "\n",
      "Test set: Average loss: 0.0349, Accuracy: 9899/10000 (98.99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.10, pruner_model=FPGMPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5358117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 29, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(29, 58, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=8352, out_features=116, bias=True)\n",
      "  (fc2): Linear(in_features=116, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0349, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (29, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 29, 26, 26) |  176436 |   290   |\n",
      "|   1   | conv2 | Conv2d | (58, 29, 3, 3) | (3, 29, 26, 26) | (3, 58, 24, 24) | 8719488 |  15196  |\n",
      "|   2   | fc1   | Linear |  (116, 8352)   |    (3, 8352)    |     (3, 116)    |  968832 |  968948 |\n",
      "|   3   | fc2   | Linear |   (10, 116)    |     (3, 116)    |     (3, 10)     |   1160  |   1170  |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 9865916\n",
      "#Params total: 985604\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, , Test-time:  1.8854s\n",
      "Finetuned model FLOPs 9.87 M, #Params: 0.99M, Accuracy:  98.99%, Test-time:  1.6135s, Speed-up:  1.17x\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e2bfe",
   "metadata": {},
   "source": [
    "## FPGM Pruner (Config-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7323ada8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.75\n",
      "conv2  sparsity :  0.75\n",
      "fc1  sparsity :  0.75\n",
      "[2022-10-02 16:34:16] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mreplace linear with new in_features: 6912, out_features: 96\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mreplace linear with new in_features: 96, out_features: 10\u001b[0m\n",
      "[2022-10-02 16:34:16] \u001b[32mspeedup done\u001b[0m\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.236769\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.142256\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.093827\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.153730\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.038276\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.013548\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.081110\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.056460\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.030072\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.149942\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.076945\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.007201\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.064737\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.140665\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.095337\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.045345\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.010021\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.082555\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.095996\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.153738\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.140697\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.009862\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.146349\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.049828\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.005953\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.046425\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.003874\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.003341\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.044716\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.018020\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.076147\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.043179\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.006203\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.062610\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.106762\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.008453\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.099425\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.015197\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.015467\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.017612\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.044701\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.065528\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.040857\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.043879\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.002494\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.121239\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.024861\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.008633\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.005488\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.102759\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.200191\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.068907\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.015221\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.048934\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.011132\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.054357\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.041063\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.228316\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.026041\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.036950\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.086106\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.072603\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.028713\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.018911\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.016942\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.122392\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.048008\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.024759\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.038874\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.065464\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.016439\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.079897\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.216465\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.014365\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.010776\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.043711\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.021844\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.136795\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.072787\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.015897\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.014267\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.039183\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.043170\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.037974\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.021986\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.270617\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.057438\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.092072\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.113677\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.019587\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.053556\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.013529\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.037250\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.193979\n",
      "\n",
      "Test set: Average loss: 0.0364, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.034222\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.011277\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.038418\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.096464\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.002065\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.016339\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.046927\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.014342\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.006101\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.025548\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.023449\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.025776\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.018227\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.013608\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.057817\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.015626\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.040937\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.038681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.018221\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.069876\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.033910\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.001359\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.015711\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.035733\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.001426\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.034201\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.006504\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.015676\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.009907\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.037884\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.156646\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.042902\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.016618\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.016276\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.030701\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.033126\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.036503\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.050632\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.012005\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.106742\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.040455\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.158025\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.068613\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.009193\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.033213\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.009400\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.010959\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.001816\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.157890\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.005637\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.143942\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.040095\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.006821\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.018760\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.003161\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.005206\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.052083\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.026415\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.007112\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.037136\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.063251\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.008405\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.186265\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.135686\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.074416\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.008417\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.149234\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.064641\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.015034\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.099853\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.031822\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.006205\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.027001\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.011928\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.006502\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.082506\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.074495\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.023335\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.022783\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.006119\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.009092\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.010999\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.017143\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.153005\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.018272\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.019756\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.020776\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.035243\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.091049\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.002157\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.037625\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.010316\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.246018\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.023954\n",
      "\n",
      "Test set: Average loss: 0.0384, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.017315\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.027078\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.035488\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.028004\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.050930\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.002712\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.027368\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.050054\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.016728\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.083980\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.003034\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.013790\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.029538\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.010088\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.061252\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.003642\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.121091\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.119385\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.034159\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.006526\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.035649\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.011370\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.084432\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.041583\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.022437\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.048293\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.001435\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.008388\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.020965\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.002584\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.041098\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.001635\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.103099\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.100737\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.012702\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.018952\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.023140\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.001516\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.004890\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.013399\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.035609\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.003595\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.005308\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.086912\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.011048\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.008606\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.017481\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.019615\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.006138\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.003949\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.011541\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.013885\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.017858\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.087096\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.000467\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.015886\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.022248\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.000634\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.008138\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.022472\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.009495\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.041731\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.036533\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.007296\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.009359\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.007169\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.028416\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.029194\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.047105\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.004364\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.054634\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.081735\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.022052\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.032940\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.017530\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.063183\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.115443\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.026088\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.012827\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.120878\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.013653\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.118419\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.008398\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.017891\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.002641\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.003403\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.010978\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.066070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.003545\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.137758\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.002055\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.115051\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.000153\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.008686\n",
      "\n",
      "Test set: Average loss: 0.0313, Accuracy: 9909/10000 (99.09%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.25, pruner_model=FPGMPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e87189c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 24, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=6912, out_features=96, bias=True)\n",
      "  (fc2): Linear(in_features=96, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0313, Accuracy: 9909/10000 (99.09%)\n",
      "\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (24, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 24, 26, 26) |  146016 |   240   |\n",
      "|   1   | conv2 | Conv2d | (48, 24, 3, 3) | (3, 24, 26, 26) | (3, 48, 24, 24) | 5971968 |  10416  |\n",
      "|   2   | fc1   | Linear |   (96, 6912)   |    (3, 6912)    |     (3, 96)     |  663552 |  663648 |\n",
      "|   3   | fc2   | Linear |    (10, 96)    |     (3, 96)     |     (3, 10)     |   960   |   970   |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 6782496\n",
      "#Params total: 675274\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, , Test-time:  1.8854s\n",
      "Finetuned model FLOPs 6.78 M, #Params: 0.68M, Accuracy:  99.09%, Test-time:  1.7455s, Speed-up:  1.08x\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e286d15",
   "metadata": {},
   "source": [
    "## FPGM Pruner (Config-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01e9e0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.5\n",
      "conv2  sparsity :  0.5\n",
      "fc1  sparsity :  0.5\n",
      "[2022-10-02 16:34:58] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mreplace linear with new in_features: 4608, out_features: 64\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mreplace linear with new in_features: 64, out_features: 10\u001b[0m\n",
      "[2022-10-02 16:34:58] \u001b[32mspeedup done\u001b[0m\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.450334\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.302304\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.122035\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.060924\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.073831\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.021779\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.053287\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.057900\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.050458\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.162642\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.222923\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.053283\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.110842\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.060786\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.032370\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.079152\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.107249\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.093264\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.231248\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.018500\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.035085\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.021901\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.051569\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.070597\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.093441\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.101317\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.068658\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.084083\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.011126\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.226334\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.018676\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.168337\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.030147\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.220558\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.015068\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.161678\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.015715\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.077527\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.111020\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.030290\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.052809\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.106346\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.030633\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.029175\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.021871\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.102890\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.097986\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.157145\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.131840\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.012705\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.024928\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.149948\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.159896\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.086330\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.010149\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.074262\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.134570\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.049344\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.143810\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.097911\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.072344\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.021882\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.029448\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.056751\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.051438\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.066657\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.178989\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.046606\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.063375\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.101312\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.152211\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.021182\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.038563\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.034096\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.013175\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.059336\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.055350\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.109843\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.027283\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.054885\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.055600\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.076970\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.040518\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.038808\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.059060\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.094686\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.186805\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.083704\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.066688\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.030726\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.186780\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.060431\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.074260\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.083191\n",
      "\n",
      "Test set: Average loss: 0.0461, Accuracy: 9866/10000 (98.66%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.019381\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.030467\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.031624\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.042705\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.134406\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.084889\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.128867\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.122849\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.090265\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.080872\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.001488\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.003786\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.185622\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.098820\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.048527\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.010685\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.051567\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.088629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.026846\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.118926\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.027041\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.052793\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.037352\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.091458\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.055662\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.014538\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.036248\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.067074\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.032503\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.098953\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.027987\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.124897\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.061640\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.057675\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.082352\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.126548\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.136818\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.053319\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.047450\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.142971\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.057760\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.030709\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.021853\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.070447\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.036516\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.050558\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.127986\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.006579\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.044221\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.042240\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.006272\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.087940\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.019741\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.116187\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.072818\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.102659\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.082305\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.068361\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.102268\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.046704\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.018358\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.023229\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.010852\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.055174\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.016573\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.053147\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.145786\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.141698\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.053941\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.111753\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.108629\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.014306\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.029725\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.026926\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.046229\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.035029\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.007102\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.084548\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.021321\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.301924\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.024070\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.067202\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.068669\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.027860\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.079485\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.023954\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.026034\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.059794\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.136851\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.132749\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.038681\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.159116\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.059647\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.026048\n",
      "\n",
      "Test set: Average loss: 0.0470, Accuracy: 9862/10000 (98.62%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.139890\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.058636\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.054748\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.094189\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.115150\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.027934\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.126284\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.087877\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.130532\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.188199\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.042983\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.100600\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.058510\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.052072\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.066399\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.040002\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.081031\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.060729\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.011475\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.064565\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.027375\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.045439\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.051139\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.054639\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.013479\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.009551\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.039378\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.011914\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.048516\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.086352\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.112978\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.034629\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.078030\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.068822\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.019731\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.021083\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.047321\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.052913\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.056435\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.050855\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.027633\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.031429\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.033758\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.010133\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.127395\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.015455\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.047499\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.024351\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.046014\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.008898\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.101053\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.034876\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.078493\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.065806\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.234263\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.038430\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.130421\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.045442\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.046841\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.026207\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.019589\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.037769\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.091503\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.118707\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.027791\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.118409\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.102754\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.033640\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.026928\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.005525\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.004293\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.162497\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.033870\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.048531\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.021872\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.089463\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.037160\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.115939\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.009411\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.166101\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.058019\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.075892\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.129650\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.014620\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.026890\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.057264\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.008859\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.207422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.089838\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.015552\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.083671\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.167920\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.085344\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.070702\n",
      "\n",
      "Test set: Average loss: 0.0346, Accuracy: 9893/10000 (98.93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.50, pruner_model=FPGMPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80b59249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=4608, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0346, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (16, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 16, 26, 26) |  97344  |   160   |\n",
      "|   1   | conv2 | Conv2d | (32, 16, 3, 3) | (3, 16, 26, 26) | (3, 32, 24, 24) | 2654208 |   4640  |\n",
      "|   2   | fc1   | Linear |   (64, 4608)   |    (3, 4608)    |     (3, 64)     |  294912 |  294976 |\n",
      "|   3   | fc2   | Linear |    (10, 64)    |     (3, 64)     |     (3, 10)     |   640   |   650   |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 3047104\n",
      "#Params total: 300426\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, , Test-time:  1.8854s\n",
      "Finetuned model FLOPs 3.05 M, #Params: 0.30M, Accuracy:  98.93%, Test-time:  1.6869s, Speed-up:  1.12x\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f3394",
   "metadata": {},
   "source": [
    "## FPGM Pruner (Config-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94c8614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.25\n",
      "conv2  sparsity :  0.25\n",
      "fc1  sparsity :  0.25\n",
      "[2022-10-02 16:35:41] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mreplace linear with new in_features: 2304, out_features: 32\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mreplace linear with new in_features: 32, out_features: 10\u001b[0m\n",
      "[2022-10-02 16:35:41] \u001b[32mspeedup done\u001b[0m\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.798149\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.649098\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.440144\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.373207\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.333228\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.176755\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.367386\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.268963\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.189112\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.232286\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.320817\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.265926\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.267495\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.104525\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.380413\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.220193\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.517859\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.208031\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.232883\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.202232\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.224344\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.316337\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.181160\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.149975\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.287979\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.210058\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.115321\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.116383\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.104293\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.147771\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.328674\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.182476\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.248358\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.115342\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.247286\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.072760\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.177070\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.095185\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.342434\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.285771\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.138536\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.240876\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.116003\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.079963\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.250585\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.297443\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.273121\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.086786\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.199034\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.204277\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.118445\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.140393\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.185025\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.576971\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.211279\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.284703\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.189630\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.119555\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.068984\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.135292\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.286023\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.334943\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.146305\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.155012\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.401849\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.204659\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.198524\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.256332\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.414074\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.362587\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.178592\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.139802\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.384837\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.092526\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.057352\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.197544\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.188803\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.199220\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.142921\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.216255\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.125421\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.180198\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.124565\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.228943\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.497767\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.299470\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.080358\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.206489\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.169466\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.110174\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.210482\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.193604\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.164519\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.128694\n",
      "\n",
      "Test set: Average loss: 0.0591, Accuracy: 9823/10000 (98.23%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.441912\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.494865\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.179647\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.286549\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.129308\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.243296\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.229302\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.135222\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.061262\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.170429\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.166382\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.110012\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.027917\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.061302\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.108879\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.205095\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.217071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.074282\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.210891\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.205690\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.247867\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.201888\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.144764\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.102260\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.110746\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.073059\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.142592\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.123317\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.373562\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.247630\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.222055\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.096412\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.162454\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.284194\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.079949\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.152596\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.179208\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.165931\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.188583\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.116059\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.102463\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.196765\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.207176\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.145841\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.214074\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.211077\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.132838\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.042591\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.099676\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.042752\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.186343\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.181540\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.186585\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.115675\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.109838\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.086169\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.165834\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.048879\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.305340\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.162366\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.347993\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.341291\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.110834\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.149474\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.124423\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.326815\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.344037\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.107006\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.059483\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.042727\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.137245\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.178415\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.168998\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.123775\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.060851\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.179087\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.172429\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.125776\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.189010\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.056513\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.170221\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.157193\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.218359\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.148268\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.293680\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.101604\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.064307\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.177281\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.133053\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.118101\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.106379\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.102598\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.144599\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.216931\n",
      "\n",
      "Test set: Average loss: 0.0503, Accuracy: 9853/10000 (98.53%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.126194\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.142435\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.111099\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.153869\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.109619\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.469122\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.332923\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.083164\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.191923\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.084002\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.131789\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.082622\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.162046\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.195393\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.200036\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.107258\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.088066\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.169995\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.054741\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.071981\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.164134\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.108402\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.141541\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.311721\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.075258\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.112842\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.136066\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.183171\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.152883\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.208400\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.105172\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.121941\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.048193\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.199715\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.131507\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.065670\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.302453\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.090228\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.094306\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.105167\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.222450\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.076070\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.151327\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.098705\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.427076\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.092383\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.174074\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.129869\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.054132\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.118966\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.170375\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.095781\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.102707\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.094150\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.166020\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.122271\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.189272\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.176841\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.547846\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.182794\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.041216\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.125351\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.334561\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.385720\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.341686\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.269532\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.405692\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.204382\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.222350\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.081115\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.194054\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.089664\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.042764\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.047669\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.164654\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.149002\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.272158\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.227057\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.093428\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.264108\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.197003\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.133110\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.084682\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.041833\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.093797\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.154741\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.111783\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.147267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.182389\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.125944\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.148449\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.343642\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.134891\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.066034\n",
      "\n",
      "Test set: Average loss: 0.0605, Accuracy: 9838/10000 (98.38%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.75, pruner_model=FPGMPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "696a4157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=2304, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0605, Accuracy: 9838/10000 (98.38%)\n",
      "\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape |   Input Size   |   Output Size   | FLOPs  | #Params |\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "|   0   | conv1 | Conv2d |  (8, 1, 3, 3) | (3, 1, 28, 28) |  (3, 8, 26, 26) | 48672  |    80   |\n",
      "|   1   | conv2 | Conv2d | (16, 8, 3, 3) | (3, 8, 26, 26) | (3, 16, 24, 24) | 663552 |   1168  |\n",
      "|   2   | fc1   | Linear |   (32, 2304)  |   (3, 2304)    |     (3, 32)     | 73728  |  73760  |\n",
      "|   3   | fc2   | Linear |    (10, 32)   |    (3, 32)     |     (3, 10)     |  320   |   330   |\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "FLOPs total: 786272\n",
      "#Params total: 75338\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, , Test-time:  1.8854s\n",
      "Finetuned model FLOPs 0.79 M, #Params: 0.08M, Accuracy:  98.38%, Test-time:  1.6755s, Speed-up:  1.13x\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
