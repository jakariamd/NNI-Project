{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559a9102",
   "metadata": {},
   "source": [
    "# Define Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63519f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from nni.compression.pytorch.speedup import ModelSpeedup\n",
    "from nni.compression.pytorch.utils import count_flops_params\n",
    "import time\n",
    "\n",
    "from mnist_model import Net, train, test, device, optimizer_scheduler_generator\n",
    "\n",
    "# define the model\n",
    "model = Net().to(device)\n",
    "\n",
    "# show the model stbructure, note that pruner will wrap the model layer.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9108c0",
   "metadata": {},
   "source": [
    "### Pre-train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e585c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302562\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.387486\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.642233\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.665975\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.373177\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.353941\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.185660\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.497059\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.297307\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.079621\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.275867\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.289521\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.345981\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.160544\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.371496\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.123943\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.218580\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.411724\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.227931\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.125327\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.160709\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.127655\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.157192\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.247380\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.207935\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.499199\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.089366\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.148529\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.064288\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.167300\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.093722\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.084013\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.228002\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.182960\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.239181\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.097810\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.197308\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.318949\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.071368\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.129240\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.070113\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.183637\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.254277\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.033095\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.096200\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.035261\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.057886\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.183238\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.179453\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.194656\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.146379\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.111069\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.044829\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.083742\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.168820\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.072356\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.172332\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.189561\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.174297\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.076936\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.101792\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.044392\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.507709\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.190315\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.069505\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.320053\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.282548\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.057297\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.039780\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.108471\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.068641\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.211133\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.049573\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.019324\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.166180\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.086915\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.240552\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.033773\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.020132\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.118663\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.092761\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.115940\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.116700\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.064535\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.085498\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.120657\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.134769\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.112503\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.210610\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.078929\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.065369\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.061280\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.120235\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.091701\n",
      "\n",
      "Test set: Average loss: 0.0455, Accuracy: 9852/10000 (98.52%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.055917\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.014424\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.060482\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.145556\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.046369\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.051565\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.101016\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.117255\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.030742\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.012255\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.050870\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.011883\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.021817\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.035014\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.043687\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.032015\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.160267\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.043253\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.118231\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.031112\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.060578\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.031424\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.221164\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.010615\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.196014\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.001697\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.101699\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.074423\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.061997\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.060665\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.011895\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.061687\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.150314\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.026983\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.019720\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.022467\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.024990\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.063630\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.016767\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.264844\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.070729\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.050775\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.025097\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.054444\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.057226\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.135517\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.142114\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.190209\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.016700\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.027161\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.004581\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.079055\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.045354\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.069798\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.175161\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.120535\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.002847\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.025983\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.110694\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.055068\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.010192\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.032483\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.078880\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.039558\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.041332\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.043769\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.047020\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.009058\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.030967\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.021605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.146690\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.007888\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.101905\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.150270\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.069143\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.169513\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.147782\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.037542\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.024494\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.025198\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.014698\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.065388\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.061681\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.204482\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.274441\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.029924\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.007490\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.140670\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.016128\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.100674\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.026531\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.044514\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.014332\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.045855\n",
      "\n",
      "Test set: Average loss: 0.0342, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.076206\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.042259\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.103740\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.038555\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.045797\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.135893\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.010967\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.009157\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.032353\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.014944\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.053252\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.008285\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.039196\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.011011\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.025950\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.048385\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.035160\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.133732\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.038149\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.002613\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.019667\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.012888\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.154146\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.012597\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.019313\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.222880\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.075124\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.116082\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.100172\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.099092\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.043753\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.154919\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.027910\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.039005\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.017478\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.289317\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.146251\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.111996\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.021817\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.067185\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.005744\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.009923\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.008131\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.106632\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.054276\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.086359\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.014169\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.055476\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.054817\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.027939\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.210674\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.001591\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.014467\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.003005\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.040851\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.034690\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.214782\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.051577\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.082714\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.262598\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.020076\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.121248\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.008875\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.035349\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.044886\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.056061\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.052579\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.063052\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.008352\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.040922\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.033932\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.166571\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.013985\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.035524\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.016062\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.068474\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.019156\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.013194\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.008808\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.012756\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.109631\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.001084\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.019560\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.191874\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.118399\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.085342\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.139834\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.020779\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.211173\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.012128\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.008588\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.099901\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.005085\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.039928\n",
      "\n",
      "Test set: Average loss: 0.0325, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.026685\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.011122\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.218301\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.015396\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.007020\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.188240\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.023728\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.023467\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.041657\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.012974\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.002489\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.139253\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.016973\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.003274\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.062492\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.005750\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.045592\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.015675\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.014260\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.088809\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.137987\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.089680\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.044817\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.030161\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.003444\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.017884\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.009357\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.014532\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.034612\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.031779\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.003700\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.019504\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.072127\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.005848\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.048544\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.013984\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.021425\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.032963\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.019206\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.046488\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.065156\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.101059\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.005885\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.231435\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.027119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.010412\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.018130\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.125797\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.269180\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.006356\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.018627\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.013846\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.080237\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.005863\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.009268\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.074000\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.018315\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.032954\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.016769\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.052394\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.037090\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.084192\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.012175\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.018936\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.036909\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.021456\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.003360\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.024092\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.024022\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.040635\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.001381\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.006933\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.120834\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.007591\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.073629\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.033593\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.008084\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.015901\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.031157\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.009503\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.010841\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.003346\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.068828\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.014619\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.001908\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.010432\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.000648\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.008936\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.020092\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.007466\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.022913\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.016021\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.021379\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.012468\n",
      "\n",
      "Test set: Average loss: 0.0318, Accuracy: 9898/10000 (98.98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.063730\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.030923\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.023100\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.010886\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.007372\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.090773\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.038889\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.012390\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.015304\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.087249\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.009695\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.006103\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.011690\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.004870\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.046360\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.006122\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.005568\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.011433\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.104596\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.064726\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.004400\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.089818\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.014793\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.012149\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.116162\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.061141\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.016028\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.036970\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.021049\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.035510\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.007339\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.013207\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.066961\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.009466\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.094730\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.014019\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.053162\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.060090\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.011119\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.013769\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.017044\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.087389\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.078469\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.187032\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.040796\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.006856\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.030394\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.025845\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.005961\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.056988\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.125141\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.007206\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.042931\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.008887\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.049227\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.017566\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.008418\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.001787\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.006811\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.043502\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.008429\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.005325\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.015161\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.025810\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.011008\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.006855\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.006750\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.033995\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.147767\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.001390\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.092392\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.046851\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.009776\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.026540\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.003688\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.037881\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.185277\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.018802\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.048381\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.007353\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.047282\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.003913\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.015435\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.021231\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.011117\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.024539\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.010408\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.002105\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.001454\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.011124\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.016257\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.026358\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.010573\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.001396\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 9919/10000 (99.19%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.119274\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.043164\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.155936\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.349060\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.083776\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.071487\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.029647\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.014436\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.001850\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.018005\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.025410\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.003021\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.006191\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.070437\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.144794\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.018269\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.003167\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.002952\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.004816\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.001959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.119042\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.075478\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.055677\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.021125\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.005599\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.012724\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.000981\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.004505\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.011068\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.058469\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.050487\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.017736\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.073709\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.012466\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.045173\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.002921\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.026066\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.033283\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.008787\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.000795\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.002428\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.033850\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.021254\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.007992\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.028345\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.018209\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.059968\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.171680\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.013839\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.022694\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.018580\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.129229\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.002163\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.002336\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.061645\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.069087\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.005448\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.018027\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.011975\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.000545\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.005176\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.012436\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.085088\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.055124\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.011089\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.072645\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.031377\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.070681\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.044554\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.059318\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.006881\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.011083\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.179618\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.091359\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.077345\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.010489\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.010545\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.099189\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.020710\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.035896\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.046831\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.002108\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.001897\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.020732\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.084126\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.049115\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.012705\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.142754\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.016903\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.003991\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.020297\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.007220\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.001781\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.002476\n",
      "\n",
      "Test set: Average loss: 0.0289, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.036807\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.184871\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.007096\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.010690\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.040359\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.154359\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.063631\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.004248\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.021744\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.004813\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.015637\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.014332\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.013319\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.068728\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.000751\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.004907\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.015681\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.001503\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.033115\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.106911\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.054035\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.017634\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.027611\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.031173\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.002565\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.000390\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.011022\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.018321\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.251846\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.010436\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.057135\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.003160\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.032622\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.016673\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.063150\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.020490\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.039792\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.091336\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.002554\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.001670\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.043454\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.030745\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.011407\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.000873\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.016183\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.023838\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.014674\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.056248\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.014125\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.007164\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.003563\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.047396\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.016970\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.005173\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.005217\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.011795\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.004634\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.000360\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.000362\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.067402\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.077445\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.072806\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.072644\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.013917\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.004031\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.001205\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.002284\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.059748\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.091310\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.013585\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.018989\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.079440\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.006571\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.058240\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.013630\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.003461\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.042328\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.057302\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.006335\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.006440\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.022653\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.032115\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.035855\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.000138\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.001414\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.017943\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.020899\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.024887\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.024129\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.000646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.020030\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.001811\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.072465\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.114921\n",
      "\n",
      "Test set: Average loss: 0.0297, Accuracy: 9912/10000 (99.12%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.014692\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.002201\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.000277\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.002066\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.020659\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.013665\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.013045\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.013267\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.001700\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.040384\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.012653\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.025664\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.002221\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.078139\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.008888\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.000674\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.028218\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.046920\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.001536\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.005190\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.042930\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.005134\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.015822\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.002763\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.021757\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.001781\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.000464\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.006446\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.004030\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.004898\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.071634\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.006709\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.006146\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.002763\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.011650\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.021910\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.003995\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.028250\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.152606\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.061355\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.002891\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.085346\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.071577\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.104461\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.020059\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.018156\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.115554\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.103645\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.020928\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.018721\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.002079\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.058943\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.003640\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.141782\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.002515\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.011302\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.002834\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.012799\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.014060\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.009780\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000502\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.000999\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.212733\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.015345\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.061440\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.001938\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.276280\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.046301\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.042652\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.045580\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.005960\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.085839\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.031980\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.020237\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.048698\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.018759\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.002452\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.057567\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.007570\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.003651\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.021190\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.019034\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.001484\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.077073\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.169040\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.017753\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.007846\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.015696\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.003880\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.003934\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.000750\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.028503\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.025908\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.037320\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.002572\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.004010\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.017210\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.030529\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.014664\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.000730\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.054359\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.006307\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.005143\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.021179\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.046696\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.009382\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.058152\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.000448\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.047732\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.079106\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.022382\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.019005\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.006848\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.041404\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.027205\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.025599\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.068118\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.005837\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.025999\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.007205\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.031365\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.005240\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.037382\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.147946\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.037580\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.177395\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.001290\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.113117\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.005303\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.001952\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.051756\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.004069\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.082628\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.046096\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.010134\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.041562\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.002165\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.078152\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.002069\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.035522\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.037782\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.025204\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.005587\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.003334\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.009310\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.032879\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.092507\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.004188\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.001951\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.007304\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.065822\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.008160\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.008273\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.006517\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.078046\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.001571\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.001743\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.090111\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.003163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.014979\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.015170\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.057694\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.000774\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.025447\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.008091\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.104055\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.015812\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.007292\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.003069\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.007727\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.001411\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.002891\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.153285\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.146831\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.037935\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.012423\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.001010\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.107236\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.003724\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.030057\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.001760\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.000512\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.022531\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.003312\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.077868\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.014604\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.026774\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.006549\n",
      "\n",
      "Test set: Average loss: 0.0291, Accuracy: 9909/10000 (99.09%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.155448\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.009902\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.055714\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.020085\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.015566\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.012903\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.011431\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.009544\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.003321\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.043538\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.059839\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.004832\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.043537\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.031804\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.006992\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.064861\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.043137\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.006885\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.002091\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.020582\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.003050\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.029328\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.006956\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.000458\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.010372\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.001565\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.002170\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.003659\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.046601\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.029302\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.001500\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.002585\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.033814\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.005431\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.011654\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.072969\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.011560\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.006359\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.005639\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.035286\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.001778\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.007965\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.008394\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.005722\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.031065\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.054956\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.026833\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.055671\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.046817\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.010534\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.017963\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.007139\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.009950\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.003023\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.005694\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.001175\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.143647\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.107275\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.004472\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.003020\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.000961\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.001677\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.018634\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.006636\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.003386\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.018258\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.006480\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.010125\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.056109\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.002563\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.009694\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.029800\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.004207\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.087394\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.014517\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.002798\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.009426\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.000568\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.006354\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.027029\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.006168\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.048222\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.010369\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.064784\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.006423\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.003624\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.001487\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.087283\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.025846\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.001798\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.008380\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.010249\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.033284\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.001706\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 9915/10000 (99.15%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the optimizer and criterion for pre-training\n",
    "optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "\n",
    "# pre-train and evaluate the model on MNIST dataset\n",
    "total_epoch = 10\n",
    "\n",
    "for epoch in range(1, total_epoch+1):\n",
    "    train(model, device, optimizer=optimizer, epoch=epoch)\n",
    "    test(model, device)\n",
    "    scheduler.step()\n",
    "    \n",
    "torch.save(model, \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4435816",
   "metadata": {},
   "source": [
    "### Performance and statistics of original model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65e18e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 9915/10000 (99.15%)\n",
      "\n",
      "elapsed time:  1.6866741180419922\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+----------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs   | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+----------+---------+\n",
      "|   0   | conv1 | Conv2d | (32, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 32, 26, 26) |  194688  |   320   |\n",
      "|   1   | conv2 | Conv2d | (64, 32, 3, 3) | (3, 32, 26, 26) | (3, 64, 24, 24) | 10616832 |  18496  |\n",
      "|   2   | fc1   | Linear |  (128, 9216)   |    (3, 9216)    |     (3, 128)    | 1179648  | 1179776 |\n",
      "|   3   | fc2   | Linear |   (10, 128)    |     (3, 128)    |     (3, 10)     |   1280   |   1290  |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+----------+---------+\n",
      "FLOPs total: 11992448\n",
      "#Params total: 1199882\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.15%\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "pre_best_acc = test(model, device)\n",
    "test_time = time.time() - start\n",
    "print('elapsed time: ', test_time)\n",
    "\n",
    "pre_flops, pre_params, _ = count_flops_params(model, torch.randn([3, 1, 28, 28]).to(device))\n",
    "print(f'Pretrained model FLOPs {pre_flops/1e6:.2f} M, #Params: {pre_params/1e6:.2f}M, Accuracy: {pre_best_acc: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba20bd",
   "metadata": {},
   "source": [
    "# Pruning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ea7c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.compression.pytorch.pruning import L1NormPruner\n",
    "from nni.compression.pytorch.pruning import L2NormPruner\n",
    "from nni.compression.pytorch.pruning import FPGMPruner\n",
    "from nni.compression.pytorch.speedup import ModelSpeedup\n",
    "\n",
    "def pruner_function(sparsity_per_layer, pruner_model):\n",
    "    config_list = [{\n",
    "        'sparsity_per_layer': sparsity_per_layer,\n",
    "        'op_types': ['Linear', 'Conv2d']\n",
    "    }, {\n",
    "        'exclude': True,\n",
    "        'op_names': ['fc2']\n",
    "    }]\n",
    "\n",
    "    model = torch.load(\"mnist_cnn.pt\")\n",
    "    model.eval()\n",
    "\n",
    "    # Using L1NormPruner to prune the model and generate the masks.\n",
    "    pruner = pruner_model(model, config_list)\n",
    "\n",
    "    # show the wrapped model structure, `PrunerModuleWrapper` have wrapped the layers that configured in the config_list.\n",
    "    print(model)\n",
    "\n",
    "    # compress the model and generate the masks\n",
    "    _, masks = pruner.compress()\n",
    "\n",
    "    # show the masks sparsity\n",
    "    print(\"Showing the masks sparsity\")\n",
    "    for name, mask in masks.items():\n",
    "        print(name, ' sparsity : ', '{:.2}'.format(mask['weight'].sum() / mask['weight'].numel()))\n",
    "\n",
    "\n",
    "    # need to unwrap the model, if the model is wrapped before speedup\n",
    "    pruner._unwrap_model()\n",
    "\n",
    "    # speedup the model, for more information about speedup, please refer :doc:`pruning_speedup`.\n",
    "    ModelSpeedup(model, torch.rand(3, 1, 28, 28).to(device), masks).speedup_model()\n",
    "\n",
    "    print(\"Model after speedup\")\n",
    "    print(model)\n",
    "\n",
    "\n",
    "    # fine- tuning model compacted model\n",
    "    # tuning and evaluate the model on MNIST dataset\n",
    "    total_epoch = 3\n",
    "\n",
    "    optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "    \n",
    "    for epoch in range(1, total_epoch + 1):\n",
    "        train(model, device, optimizer=optimizer, epoch=epoch)\n",
    "        test(model, device)\n",
    "        scheduler.step()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53bb83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perfomance_function(model):\n",
    "    start = time.time()\n",
    "    best_acc = test(model, device)\n",
    "    test_time = time.time() - start\n",
    "\n",
    "    print('elapsed time: ', test_time)\n",
    "\n",
    "    flops, params, _ = count_flops_params(model, torch.randn([3, 1, 28, 28]).to(device))\n",
    "\n",
    "    print(f'Pretrained model FLOPs {pre_flops/1e6:.2f} M, #Params: {pre_params/1e6:.2f}M, Accuracy: {pre_best_acc: .2f}%')\n",
    "    print(f'Finetuned model FLOPs {flops/1e6:.2f} M, #Params: {params/1e6:.2f}M, Accuracy: {best_acc: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1029e382",
   "metadata": {},
   "source": [
    "## L1 Norm Pruner (Config-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a50b59d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): PrunerModuleWrapper(\n",
      "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (conv2): PrunerModuleWrapper(\n",
      "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): PrunerModuleWrapper(\n",
      "    (module): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.91\n",
      "conv2  sparsity :  0.91\n",
      "fc1  sparsity :  0.91\n",
      "[2022-10-02 15:04:28] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mreplace linear with new in_features: 8352, out_features: 116\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mreplace linear with new in_features: 116, out_features: 10\u001b[0m\n",
      "[2022-10-02 15:04:28] \u001b[32mspeedup done\u001b[0m\n",
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 29, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(29, 58, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=8352, out_features=116, bias=True)\n",
      "  (fc2): Linear(in_features=116, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakaria/.local/lib/python3.10/site-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:482.)\n",
      "  return self._grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.052192\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.009384\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.023187\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.291787\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.059833\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.011270\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.003558\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.150810\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.060215\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.058111\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.147077\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.055453\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.004361\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.272022\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.028564\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.238445\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.014977\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.037701\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.061224\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.024692\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.005230\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.014766\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.011740\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.035524\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.068490\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.041223\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.017372\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.093879\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.025995\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.011213\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.025121\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.011027\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.096470\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.021139\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.028200\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.087107\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.042111\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.055559\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.024539\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.015965\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.124541\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.148500\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.133895\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.049481\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.008138\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.048289\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.227125\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.003833\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.016357\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.057766\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.005514\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.005575\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.032403\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.023977\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.032923\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.019792\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.020811\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.030614\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.003076\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.032700\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.013961\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.041739\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.018633\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.129776\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.038995\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.023155\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.005566\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.136680\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.083294\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.055025\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.087149\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.034693\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.021418\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.012649\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.017801\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.090793\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.003247\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.002036\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.001811\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.018955\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.317022\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.022200\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.022235\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.059438\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.005412\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.004541\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.022698\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.040467\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.000286\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.125392\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.004700\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.087931\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.005844\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.056948\n",
      "\n",
      "Test set: Average loss: 0.0371, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.009641\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.053181\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.001741\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.016840\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.010927\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.030799\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.129720\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.222542\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.022715\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.026578\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.118341\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.041065\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.080798\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.066187\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.013779\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.052437\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.089216\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.026159\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.133916\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.142140\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.033174\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.099756\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.018366\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.035822\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.097653\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.006678\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.034322\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.017455\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.029034\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.041581\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.095266\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.379838\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.006148\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.092052\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.190006\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.013013\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.041554\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.015910\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.008615\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.002842\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.015058\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.000678\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.115039\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.133361\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.024823\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.005628\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.009349\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.047569\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.012508\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.020450\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.037790\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.015450\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.004136\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.004897\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.009088\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.126014\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.096501\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.139166\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.042452\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.001143\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.005546\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.003986\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.162550\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.070207\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.006589\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.005287\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.002127\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.044467\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.038045\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.010930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.009712\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.011324\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.009120\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.012098\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.018854\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.077943\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.032495\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.033970\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.046511\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.093389\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.075986\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.070750\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.003093\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.034122\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.026528\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.029540\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.028541\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.022657\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.038446\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.148613\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.003503\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.140709\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.004531\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.063673\n",
      "\n",
      "Test set: Average loss: 0.0324, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.023896\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.002471\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.032416\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.005502\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.036475\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.119221\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.076261\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.001447\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.065003\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.041640\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.048691\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.014400\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.007816\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.065682\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.077251\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.044489\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.006180\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.120734\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.127994\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.008005\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.077279\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.041000\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.001496\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.011949\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.009360\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.023261\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.024484\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.005525\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.002830\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.013655\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.000144\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.005815\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.019614\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.041981\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.007234\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.019505\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.013848\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.005900\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.002792\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.006378\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.002622\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.000042\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.008981\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.077220\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.099669\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.004122\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.025190\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.064725\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.011070\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.018732\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.129007\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.076316\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.027424\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.022595\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.002666\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.044728\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.013640\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.087889\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.021593\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.022764\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.005983\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.125260\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.116919\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.017250\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.038674\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.003261\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.008253\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.009265\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.068485\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.007249\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.006459\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.004819\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.030268\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.006048\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.051684\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.008137\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.009568\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.005129\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.049442\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.001081\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.060225\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.014928\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.058366\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.003595\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.007410\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.004721\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.001913\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.007229\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.019535\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.023088\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.065728\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.119308\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.016943\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.168313\n",
      "\n",
      "Test set: Average loss: 0.0300, Accuracy: 9911/10000 (99.11%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.10, pruner_model=L1NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd5dc068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0300, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "elapsed time:  1.8643689155578613\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (29, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 29, 26, 26) |  176436 |   290   |\n",
      "|   1   | conv2 | Conv2d | (58, 29, 3, 3) | (3, 29, 26, 26) | (3, 58, 24, 24) | 8719488 |  15196  |\n",
      "|   2   | fc1   | Linear |  (116, 8352)   |    (3, 8352)    |     (3, 116)    |  968832 |  968948 |\n",
      "|   3   | fc2   | Linear |   (10, 116)    |     (3, 116)    |     (3, 10)     |   1160  |   1170  |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 9865916\n",
      "#Params total: 985604\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.15%\n",
      "Finetuned model FLOPs 9.87 M, #Params: 0.99M, Accuracy:  99.11%\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7ad48e",
   "metadata": {},
   "source": [
    "## L1 Norm Pruner (Config-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e99fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): PrunerModuleWrapper(\n",
      "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (conv2): PrunerModuleWrapper(\n",
      "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): PrunerModuleWrapper(\n",
      "    (module): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.75\n",
      "conv2  sparsity :  0.75\n",
      "fc1  sparsity :  0.75\n",
      "[2022-10-02 15:05:18] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mreplace linear with new in_features: 6912, out_features: 96\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mreplace linear with new in_features: 96, out_features: 10\u001b[0m\n",
      "[2022-10-02 15:05:18] \u001b[32mspeedup done\u001b[0m\n",
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 24, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=6912, out_features=96, bias=True)\n",
      "  (fc2): Linear(in_features=96, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.011284\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.175350\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.030196\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.061794\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.146923\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.165736\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.026378\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.013461\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.043985\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.020477\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.015060\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.005694\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.039684\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.004120\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.084956\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.029272\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.040613\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.005246\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.026396\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.098159\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.022930\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.005937\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.029105\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.109687\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.109907\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.003155\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.081070\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.120165\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.062549\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.082235\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.163571\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.071908\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.029601\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.062562\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.013335\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.057000\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.045916\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.088549\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.026166\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.224922\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.001546\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.082538\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.049793\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.020947\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.077212\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.013035\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.006221\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.209726\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.033351\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.086276\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.080581\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.010206\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.005452\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.032571\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.063513\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.084994\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.014584\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.043288\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.010848\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.127701\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.004127\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.011652\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.036585\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.073743\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.014376\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.190170\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.023451\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.003130\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.005642\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.036400\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.097239\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.006196\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.053962\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.009855\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.171151\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.094314\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.088950\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.012095\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.037042\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.050242\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.042215\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.037772\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.041196\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.061798\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.024165\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.048723\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.157844\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.272382\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.049548\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.018925\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.010867\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.033682\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.004208\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.009833\n",
      "\n",
      "Test set: Average loss: 0.0429, Accuracy: 9856/10000 (98.56%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.034904\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.026090\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.049695\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.013823\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.076610\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.039389\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.029210\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.202583\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.123843\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.005021\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.152507\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.011477\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.037689\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.012626\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.075472\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.017463\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.062245\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.006870\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.081184\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.068504\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.032649\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.057547\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.117736\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.016965\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.004208\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.008206\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.043630\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.136697\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.001412\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.039682\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.003617\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.138252\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.026761\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.041946\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.002991\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.040447\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.014507\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.117819\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.072143\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.172667\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.011259\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.067708\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.007022\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.011975\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.000659\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.002103\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.086388\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.056610\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.024293\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.047858\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.064565\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.020321\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.068327\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.017365\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.028010\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.005876\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.118452\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.009443\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.023686\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.013323\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.000765\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.067469\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.017477\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.204198\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.081043\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.020107\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.027131\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.061983\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.062101\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.007779\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.027754\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.009873\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.004397\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.180002\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.014363\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.008498\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.016816\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.028715\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.042327\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.123420\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.001452\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.001043\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.071477\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.060181\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.006988\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.029238\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.017590\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.049149\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.024785\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.003460\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.011161\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.019003\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.067241\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.019665\n",
      "\n",
      "Test set: Average loss: 0.0385, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.026165\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.083757\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.006750\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.049343\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.043567\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.004358\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.001060\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.004254\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.011579\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.013676\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.080015\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.009741\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.007648\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.122746\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.071421\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.013433\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.015769\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.079878\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.049998\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.000871\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.065254\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.015353\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.001363\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.009102\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.004909\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.005891\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.014221\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.010482\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.061009\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.003541\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.004801\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.014665\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.055358\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.008671\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.000914\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.000350\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.008704\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.031784\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.051912\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.003875\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.097018\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.046060\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.161751\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.003937\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.036385\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.002880\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.112247\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.003132\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.093493\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.107720\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.007938\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.043782\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.061900\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.104793\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.015463\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.042003\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.035827\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.013093\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.024418\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.001227\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.205708\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.009118\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.002985\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.019623\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.069844\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.009679\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.006767\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.004776\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.019426\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.031726\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.016480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.057541\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.084232\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.024183\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.066214\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.005524\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.020690\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.088627\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.041959\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.004518\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.125844\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.123926\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.010357\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.040427\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.005881\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.174835\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.000993\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.013081\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.028471\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.003073\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.109069\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.109753\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.008090\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.011956\n",
      "\n",
      "Test set: Average loss: 0.0314, Accuracy: 9907/10000 (99.07%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.25, pruner_model=L1NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21ac7aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0314, Accuracy: 9907/10000 (99.07%)\n",
      "\n",
      "elapsed time:  1.6310503482818604\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (24, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 24, 26, 26) |  146016 |   240   |\n",
      "|   1   | conv2 | Conv2d | (48, 24, 3, 3) | (3, 24, 26, 26) | (3, 48, 24, 24) | 5971968 |  10416  |\n",
      "|   2   | fc1   | Linear |   (96, 6912)   |    (3, 6912)    |     (3, 96)     |  663552 |  663648 |\n",
      "|   3   | fc2   | Linear |    (10, 96)    |     (3, 96)     |     (3, 10)     |   960   |   970   |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 6782496\n",
      "#Params total: 675274\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.15%\n",
      "Finetuned model FLOPs 6.78 M, #Params: 0.68M, Accuracy:  99.07%\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e81cb",
   "metadata": {},
   "source": [
    "## L1 Norm Pruner (Config-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8724439c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): PrunerModuleWrapper(\n",
      "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (conv2): PrunerModuleWrapper(\n",
      "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): PrunerModuleWrapper(\n",
      "    (module): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.5\n",
      "conv2  sparsity :  0.5\n",
      "fc1  sparsity :  0.5\n",
      "[2022-10-02 15:05:59] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mreplace linear with new in_features: 4608, out_features: 64\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mreplace linear with new in_features: 64, out_features: 10\u001b[0m\n",
      "[2022-10-02 15:05:59] \u001b[32mspeedup done\u001b[0m\n",
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=4608, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.647112\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.264858\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.301706\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.014699\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.040871\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.124988\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.137794\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.138474\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.115000\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.082836\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.100622\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.052150\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.115154\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.190664\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.082410\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.099366\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.066258\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.105969\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.107041\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.142149\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.120040\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.067968\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.108625\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.041551\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.005828\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.055875\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.088907\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.052007\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.040299\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.171488\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.120551\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.047451\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.045522\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.066474\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.154903\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.353220\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.093930\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.040499\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.105484\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.082845\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.111009\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.042837\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.074759\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.084970\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.056114\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.105756\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.039203\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.412301\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.117161\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.053146\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.132581\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.110302\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.057566\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.038305\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.075940\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.057990\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.062413\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.032911\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.022892\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.062493\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.083213\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.084198\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.129730\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.013585\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.052934\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.057022\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.107800\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.009658\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.071081\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.073750\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.029500\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.118970\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.055302\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.054959\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.100581\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.114513\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.130553\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.139663\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.422345\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.063356\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.194043\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.134814\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.078637\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.010713\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.043624\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.192950\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.068451\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.014160\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.067502\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.015722\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.013251\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.090398\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.028310\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.177314\n",
      "\n",
      "Test set: Average loss: 0.0402, Accuracy: 9865/10000 (98.65%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.039229\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.057655\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.059687\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.022885\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.014134\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.093102\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.042054\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.029877\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.053930\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.019450\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.023379\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.100347\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.019462\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.104618\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.135447\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.057049\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.094380\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.118372\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.033922\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.148393\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.109955\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.081622\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.026300\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.275664\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.061654\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.043278\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.018077\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.044380\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.102081\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.023873\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.015551\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.079216\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.002091\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.030848\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.109422\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.078211\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.057808\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.077892\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.046600\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.055411\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.172147\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.046402\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.013506\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.015411\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.042578\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.043516\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.062374\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.025237\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.013313\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.063675\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.011295\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.093483\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.057577\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.118760\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.007642\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.021033\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.179983\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.026777\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.087756\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.026235\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.036993\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.012380\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.155566\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.048784\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.087736\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.143238\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.017052\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.048564\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.053599\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.073019\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.112956\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.211776\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.142662\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.065701\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.065775\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.061351\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.041355\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.022594\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.076448\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.148189\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.011170\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.054873\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.062400\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.135661\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.025498\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.030948\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.007997\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.015043\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.012268\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.075273\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.057104\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.032444\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.017388\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.027663\n",
      "\n",
      "Test set: Average loss: 0.0369, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.024347\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.003463\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.040672\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.079745\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.017572\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.102921\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.016454\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.032012\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.121033\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.033512\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.044907\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.118237\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.109336\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.179792\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.004800\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.180218\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.113493\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.037008\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.041825\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.030245\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.037593\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.035617\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.021090\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.021109\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.019126\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.012239\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.148226\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.000557\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.185915\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.139755\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.010255\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.128436\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.038913\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.039847\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.150954\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.009424\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.015267\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.036598\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.018663\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.072010\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.084162\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.024287\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.061812\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.042183\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.001415\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.140618\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.029863\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.030702\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.027382\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.004453\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.153413\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.027167\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.072186\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.060423\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.008239\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.061841\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.103774\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.218251\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.006759\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.003380\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.022006\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.012167\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.035815\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.119256\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.005486\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.097790\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.085556\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.067449\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.170631\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.008605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.009476\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.069398\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.082647\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.025999\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.034199\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.139733\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.021919\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.010602\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.148870\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.035590\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.018467\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.114312\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.130064\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.002384\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.013354\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.100990\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.060686\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.068506\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.082799\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.064959\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.059337\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.065876\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.022161\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.033022\n",
      "\n",
      "Test set: Average loss: 0.0372, Accuracy: 9896/10000 (98.96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.50, pruner_model=L1NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c696ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0372, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "elapsed time:  1.5789055824279785\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (16, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 16, 26, 26) |  97344  |   160   |\n",
      "|   1   | conv2 | Conv2d | (32, 16, 3, 3) | (3, 16, 26, 26) | (3, 32, 24, 24) | 2654208 |   4640  |\n",
      "|   2   | fc1   | Linear |   (64, 4608)   |    (3, 4608)    |     (3, 64)     |  294912 |  294976 |\n",
      "|   3   | fc2   | Linear |    (10, 64)    |     (3, 64)     |     (3, 10)     |   640   |   650   |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 3047104\n",
      "#Params total: 300426\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.15%\n",
      "Finetuned model FLOPs 3.05 M, #Params: 0.30M, Accuracy:  98.96%\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223df22",
   "metadata": {},
   "source": [
    "## L1 Norm Pruner (Config-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db5ba44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): PrunerModuleWrapper(\n",
      "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (conv2): PrunerModuleWrapper(\n",
      "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): PrunerModuleWrapper(\n",
      "    (module): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.25\n",
      "conv2  sparsity :  0.25\n",
      "fc1  sparsity :  0.25\n",
      "[2022-10-02 15:06:38] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mreplace linear with new in_features: 2304, out_features: 32\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mreplace linear with new in_features: 32, out_features: 10\u001b[0m\n",
      "[2022-10-02 15:06:38] \u001b[32mspeedup done\u001b[0m\n",
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=2304, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.828945\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.761850\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.516186\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.345304\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.409519\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.339348\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.300402\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.481833\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.133708\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.174779\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.270471\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.196551\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.187759\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.211877\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.199573\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.154955\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.311830\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.282932\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.205592\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.202141\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.235493\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.376282\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.166444\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.178377\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.110838\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.151927\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.226947\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.052804\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.228802\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.226742\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.234010\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.128352\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.140417\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.150992\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.160966\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.139718\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.302756\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.146263\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.119850\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.312627\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.166607\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.210764\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.111328\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.210999\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.103565\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.135766\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.065361\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.161623\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.278196\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.356453\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.275098\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.107404\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.247822\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.123720\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.106744\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.176470\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.140371\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.132506\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.228249\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.036293\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.096194\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.115468\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.069101\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.184721\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.372847\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.321417\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.454763\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.133621\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.087665\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.162230\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.119991\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.129027\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.214577\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.074287\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.056116\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.339426\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.207410\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.202514\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.162532\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.150506\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.123141\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.089074\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.296231\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.176643\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.266671\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.141966\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.228251\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.197805\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.208287\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.247059\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.087882\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.345667\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.136440\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.193186\n",
      "\n",
      "Test set: Average loss: 0.0555, Accuracy: 9827/10000 (98.27%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.151968\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.222339\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.179179\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.110701\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.085400\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.155071\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.124994\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.269909\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.102918\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.304426\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.376693\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.136331\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.089840\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.263300\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.216225\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.054054\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.189628\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.082818\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.246291\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.250125\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.172623\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.125637\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.107857\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.163937\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.169537\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.194452\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.103856\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.206549\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.137193\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.131797\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.226512\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.417927\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.164498\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.055679\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.217898\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.188748\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.161945\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.071274\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.138237\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.130434\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.114850\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.201353\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.095472\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.213432\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.222187\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.312030\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.112855\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.247881\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.164291\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.417171\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.175674\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.305689\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.085668\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.082409\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.034486\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.101133\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.120579\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.173522\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.163914\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.298315\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.087729\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.373944\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.308152\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.161585\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.133472\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.224894\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.165952\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.123075\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.168205\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.202204\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.147928\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.259772\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.149910\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.248555\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.118660\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.127509\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.183111\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.193267\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.156349\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.281644\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.174860\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.085171\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.107493\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.110145\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.265815\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.126518\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.510663\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.325426\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.294298\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.095112\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.096458\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.161713\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.368909\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.267591\n",
      "\n",
      "Test set: Average loss: 0.0476, Accuracy: 9860/10000 (98.60%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.058163\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.142022\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.042380\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.170972\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.208403\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.070764\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.044431\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.118509\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.180204\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.110842\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.063041\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.105233\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.214409\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.308897\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.186492\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.168830\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.060912\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.174779\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.035227\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.049021\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.115081\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.221550\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.143015\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.105288\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.118985\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.178362\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.223595\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.175519\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.102277\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.088195\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.132579\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.121918\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.198896\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.156660\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.239668\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.168557\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.087174\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.087019\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.248047\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.040489\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.441787\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.179876\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.097435\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.199252\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.057236\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.101638\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.102594\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.090462\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.180459\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.060881\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.226926\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.274164\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.094094\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.079664\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.083747\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.378819\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.143652\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.198191\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.148302\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.058664\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.191856\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.280598\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.289550\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.222249\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.114650\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.147598\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.045232\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.201493\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.068133\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.155284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.225209\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.279710\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.169326\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.089866\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.096638\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.101365\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.197305\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.059957\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.180446\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.199851\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.113429\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.133909\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.113663\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.401110\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.077701\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.250002\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.176790\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.207785\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.063619\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.033644\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.130287\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.113958\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.232970\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.125546\n",
      "\n",
      "Test set: Average loss: 0.0461, Accuracy: 9864/10000 (98.64%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.75, pruner_model=L1NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60f3aa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0461, Accuracy: 9864/10000 (98.64%)\n",
      "\n",
      "elapsed time:  1.5167913436889648\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape |   Input Size   |   Output Size   | FLOPs  | #Params |\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "|   0   | conv1 | Conv2d |  (8, 1, 3, 3) | (3, 1, 28, 28) |  (3, 8, 26, 26) | 48672  |    80   |\n",
      "|   1   | conv2 | Conv2d | (16, 8, 3, 3) | (3, 8, 26, 26) | (3, 16, 24, 24) | 663552 |   1168  |\n",
      "|   2   | fc1   | Linear |   (32, 2304)  |   (3, 2304)    |     (3, 32)     | 73728  |  73760  |\n",
      "|   3   | fc2   | Linear |    (10, 32)   |    (3, 32)     |     (3, 10)     |  320   |   330   |\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "FLOPs total: 786272\n",
      "#Params total: 75338\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.15%\n",
      "Finetuned model FLOPs 0.79 M, #Params: 0.08M, Accuracy:  98.64%\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe045aec",
   "metadata": {},
   "source": [
    "## L2 Norm Pruner (Config 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "810c999b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): PrunerModuleWrapper(\n",
      "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (conv2): PrunerModuleWrapper(\n",
      "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): PrunerModuleWrapper(\n",
      "    (module): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.91\n",
      "conv2  sparsity :  0.91\n",
      "fc1  sparsity :  0.91\n",
      "[2022-10-02 15:07:16] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mreplace linear with new in_features: 8352, out_features: 116\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mreplace linear with new in_features: 116, out_features: 10\u001b[0m\n",
      "[2022-10-02 15:07:16] \u001b[32mspeedup done\u001b[0m\n",
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 29, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(29, 58, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=8352, out_features=116, bias=True)\n",
      "  (fc2): Linear(in_features=116, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.045181\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.148839\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.113642\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.113797\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.290950\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.075660\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.055430\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.101373\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.006371\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.003691\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.047021\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.036963\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.085141\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.027410\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.103209\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.140324\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.017210\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.059777\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.005829\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.165216\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.039993\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.042711\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.035004\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.002249\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.229905\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.092583\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.015122\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.029795\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.002536\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.004753\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.007337\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.106460\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.086365\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.065070\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.016907\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.050851\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.276118\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.012751\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.142999\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.057307\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.073129\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.132532\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.015472\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.008793\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.046638\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.096291\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.157218\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.023659\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.028391\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.000338\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.059422\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.040543\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.006550\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.022714\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.203820\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.106020\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.038116\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.129075\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.025811\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.012724\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.032959\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.008666\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.000899\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.009771\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.006437\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.001428\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.067948\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.049176\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.077272\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.018553\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.076425\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.033918\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.087563\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.123595\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.036073\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.042614\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.016130\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.159632\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.045273\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.057518\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.214557\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.045113\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.040381\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.081983\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.048819\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.160230\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.026029\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.041269\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.015040\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.007374\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.002046\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.060522\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.043916\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.005119\n",
      "\n",
      "Test set: Average loss: 0.0374, Accuracy: 9885/10000 (98.85%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.059021\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.086162\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.060037\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.019425\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.273300\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.000110\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.006267\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.053090\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.042621\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.092942\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.018496\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.005343\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.016952\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.039718\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.053712\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.402355\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.013492\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.055510\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.066540\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.024136\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.008771\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.050999\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.073575\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.065339\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.033479\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.097828\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.043156\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.009313\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.158028\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.011157\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.006258\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.009345\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.017427\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.006065\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.059523\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.026371\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.112872\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.023675\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.031913\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.010213\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.001542\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.194565\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.001236\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.061079\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.151880\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.026199\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.126318\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.060676\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.024450\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.001453\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.084396\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.002815\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.000250\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.019941\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.244860\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.011543\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.031267\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.066334\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.001344\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.024033\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.052655\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.014357\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.068745\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.005235\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.069417\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.026621\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.106143\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.172839\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.031012\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.011291\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.015690\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.000453\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.012566\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.037281\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.007530\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.306149\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.002318\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.036345\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.004098\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.025018\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.062396\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.014038\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.065103\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.004239\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.088274\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.130365\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.005632\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.017503\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.049712\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.036771\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.038877\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.022137\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.048489\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.145066\n",
      "\n",
      "Test set: Average loss: 0.0345, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.212284\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.097158\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.081231\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.000965\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.065434\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.089247\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.016353\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.023128\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.065672\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.048397\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.024216\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.006002\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.014589\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.006582\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.033337\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.064369\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.018631\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.038596\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.018373\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.003571\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.024525\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.012613\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.000164\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.095894\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.002043\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.080072\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.090085\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.015397\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.011671\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.001122\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.019970\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.037668\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.031247\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.042230\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.004538\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.003025\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.069882\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.002104\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.012087\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.003004\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.061163\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.060049\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.006915\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.015669\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.011734\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.007251\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.011232\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.007854\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.001227\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.074688\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.004232\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.001243\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.033950\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.004080\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.003972\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.015396\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.029315\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.019967\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.018401\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.008767\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.056335\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.001391\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.020915\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.040964\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.009933\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.011021\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.082436\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.022055\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.001095\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.003771\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.006555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.024670\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.151180\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.051261\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.010628\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.044123\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.007332\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.027795\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.052174\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.000781\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.000049\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.008640\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.001340\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.004106\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.259273\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.060975\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.002609\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.061880\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.036739\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.160101\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.001855\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.059824\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.059830\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.002051\n",
      "\n",
      "Test set: Average loss: 0.0283, Accuracy: 9909/10000 (99.09%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.10, pruner_model=L2NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc530ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0283, Accuracy: 9909/10000 (99.09%)\n",
      "\n",
      "elapsed time:  1.6711695194244385\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (29, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 29, 26, 26) |  176436 |   290   |\n",
      "|   1   | conv2 | Conv2d | (58, 29, 3, 3) | (3, 29, 26, 26) | (3, 58, 24, 24) | 8719488 |  15196  |\n",
      "|   2   | fc1   | Linear |  (116, 8352)   |    (3, 8352)    |     (3, 116)    |  968832 |  968948 |\n",
      "|   3   | fc2   | Linear |   (10, 116)    |     (3, 116)    |     (3, 10)     |   1160  |   1170  |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 9865916\n",
      "#Params total: 985604\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.15%\n",
      "Finetuned model FLOPs 9.87 M, #Params: 0.99M, Accuracy:  99.09%\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b4ec86",
   "metadata": {},
   "source": [
    "## L2 Norm Pruner (Config 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd32919b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): PrunerModuleWrapper(\n",
      "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (conv2): PrunerModuleWrapper(\n",
      "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): PrunerModuleWrapper(\n",
      "    (module): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.75\n",
      "conv2  sparsity :  0.75\n",
      "fc1  sparsity :  0.75\n",
      "[2022-10-02 15:08:05] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mreplace linear with new in_features: 6912, out_features: 96\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mreplace linear with new in_features: 96, out_features: 10\u001b[0m\n",
      "[2022-10-02 15:08:05] \u001b[32mspeedup done\u001b[0m\n",
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 24, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=6912, out_features=96, bias=True)\n",
      "  (fc2): Linear(in_features=96, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.148859\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.036310\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.128987\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.005676\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.047494\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.028581\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.008864\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.013963\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.068253\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.155138\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.031851\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.107854\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.076587\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.125182\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.084572\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.104040\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.042194\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.013823\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.021356\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.148911\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.037194\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.030215\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.105685\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.084413\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.010890\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.012149\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.020164\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.029285\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.007972\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.043025\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.024663\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.278351\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.031205\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.095036\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.013241\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.031699\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.038437\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.022785\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.061231\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.003706\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.003957\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.012314\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.041265\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.013856\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.273440\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.024750\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.222468\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.029889\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.023092\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.029648\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.004431\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.005379\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.045529\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.005685\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.021774\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.020946\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.027698\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.071944\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.180638\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.003919\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.002960\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.023181\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.101167\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.034622\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.108566\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.012778\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.007768\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.087392\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.017875\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.030734\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.045297\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.015641\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.117759\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.001621\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.079807\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.061861\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.018738\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.138039\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.016960\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.057112\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.041272\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.003201\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.011400\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.010883\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.039515\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.035733\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.010068\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.001855\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.065472\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.004942\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.034221\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.058861\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.017320\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.012819\n",
      "\n",
      "Test set: Average loss: 0.0416, Accuracy: 9889/10000 (98.89%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.001469\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.030604\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.001791\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.003775\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.081982\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.025556\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.038598\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.019565\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.004199\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.040196\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.114027\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.141943\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.013830\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.039319\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.201975\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.017700\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.012337\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.070226\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.174989\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.015534\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.003794\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.000144\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.056109\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.047929\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.123393\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.091214\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.073078\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.006836\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.028997\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.019626\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.023415\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.026926\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.007010\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.132676\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.056843\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.095966\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.017794\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.009929\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.018945\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.029388\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.014969\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.112523\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.020392\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.100894\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.021846\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.034008\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.023646\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.012132\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.014227\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.013731\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.179120\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.046958\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.018168\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.126474\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.010622\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.004640\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.173381\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.080761\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.076082\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.063322\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.021350\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.185820\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.024446\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.036092\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.066965\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.167380\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.017733\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.026415\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.019788\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.007624\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.098590\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.012147\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.005250\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.067019\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.132636\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.030819\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.040183\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.147039\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.016330\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.008802\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.050254\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.140732\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.015553\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.000440\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.025370\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.013830\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.041986\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.072153\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.038321\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.009026\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.067431\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.009156\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.018464\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.003267\n",
      "\n",
      "Test set: Average loss: 0.0403, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.034376\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.012288\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.073599\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.076324\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.031110\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.044006\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.002561\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.001514\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.005806\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.002353\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.119502\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.009671\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.010951\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.052794\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.005236\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.031492\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.017728\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.079841\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.157246\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.039665\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.100838\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.012644\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.014862\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.024659\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.007888\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.009585\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.041694\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.095955\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.079394\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.001225\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.004456\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.004458\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.158767\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.006987\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.002442\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.062711\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.031602\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.028196\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.031305\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.005384\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.027395\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.013576\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.030101\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.001930\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.042556\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.015695\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.000509\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.001753\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.003482\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.019611\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.127102\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.059116\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.008276\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.003973\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.008625\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.014550\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.000463\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.008216\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.058931\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.006164\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.000399\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.286464\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.123843\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.045384\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.001384\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.088561\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.005983\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.000667\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.021003\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.125067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.070821\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.067140\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.006197\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.049595\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.118094\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.031471\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.072482\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.005037\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.006831\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.028565\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.010637\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.005367\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.011147\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.072200\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.001417\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.005339\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.041696\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.001336\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.010850\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.009485\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.004020\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.000594\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.031466\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.170382\n",
      "\n",
      "Test set: Average loss: 0.0337, Accuracy: 9908/10000 (99.08%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.25, pruner_model=L2NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d5eb215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0337, Accuracy: 9908/10000 (99.08%)\n",
      "\n",
      "elapsed time:  1.5160517692565918\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (24, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 24, 26, 26) |  146016 |   240   |\n",
      "|   1   | conv2 | Conv2d | (48, 24, 3, 3) | (3, 24, 26, 26) | (3, 48, 24, 24) | 5971968 |  10416  |\n",
      "|   2   | fc1   | Linear |   (96, 6912)   |    (3, 6912)    |     (3, 96)     |  663552 |  663648 |\n",
      "|   3   | fc2   | Linear |    (10, 96)    |     (3, 96)     |     (3, 10)     |   960   |   970   |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 6782496\n",
      "#Params total: 675274\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.15%\n",
      "Finetuned model FLOPs 6.78 M, #Params: 0.68M, Accuracy:  99.08%\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b5d54c",
   "metadata": {},
   "source": [
    "## L2 Norm Pruner (Config 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "300e93fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): PrunerModuleWrapper(\n",
      "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (conv2): PrunerModuleWrapper(\n",
      "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): PrunerModuleWrapper(\n",
      "    (module): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.5\n",
      "conv2  sparsity :  0.5\n",
      "fc1  sparsity :  0.5\n",
      "[2022-10-02 15:08:48] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mreplace linear with new in_features: 4608, out_features: 64\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mreplace linear with new in_features: 64, out_features: 10\u001b[0m\n",
      "[2022-10-02 15:08:48] \u001b[32mspeedup done\u001b[0m\n",
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=4608, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.581371\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.101034\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.082820\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.089720\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.154992\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.220610\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.127113\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.030724\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.140209\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.033782\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.044111\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.134002\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.191838\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.039172\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.041165\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.141838\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.053944\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.094185\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.046270\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.088809\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.074769\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.041635\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.059905\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.146244\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.119071\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.128061\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.029970\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.126755\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.177393\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.018666\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.113133\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.073468\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.036483\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.083284\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.075763\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.041125\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.101869\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.137671\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.023480\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.058694\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.319802\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.049874\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.053571\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.030907\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.030478\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.049065\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.051604\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.034993\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.015919\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.046576\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.073727\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.010903\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.021840\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.031380\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.030310\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.125402\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.189199\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.022806\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.114764\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.015546\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.026598\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.120165\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.108904\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.463792\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.075215\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.019465\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.159918\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.046178\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.007660\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.040711\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.061637\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.020478\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.126885\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.093408\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.024464\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.021817\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.011372\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.090895\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.045268\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.121764\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.122613\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.096861\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.070809\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.058993\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.193780\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.040417\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.238018\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.012595\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.034927\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.055611\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.046642\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.106690\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.024515\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.091756\n",
      "\n",
      "Test set: Average loss: 0.0470, Accuracy: 9863/10000 (98.63%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.182102\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.131065\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.068721\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.040611\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.010446\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.023118\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.022961\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.016770\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.096782\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.049411\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.017381\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.033467\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.080560\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.044672\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.009534\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.053456\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.011119\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.164429\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.045680\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.079276\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.068780\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.325034\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.040563\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.043013\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.093416\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.016265\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.053013\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.077828\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.070415\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.135975\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.022312\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.223706\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.086612\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.246191\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.033561\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.208095\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.016754\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.118522\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.182031\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.033874\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.021378\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.104708\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.060061\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.030134\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.333743\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.046769\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.074124\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.142846\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.080876\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.246422\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.018565\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.021507\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.015371\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.030695\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.035395\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.073217\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.169457\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.052315\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.012801\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.066660\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.362456\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.066586\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.144079\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.059318\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.014782\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.029854\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.134269\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.131143\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.075841\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.004460\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.159289\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.105136\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.010861\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.089530\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.042215\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.100321\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.111014\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.028335\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.057596\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.040723\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.022326\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.007876\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.066982\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.061787\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.222207\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.158945\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.009053\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.050521\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.239315\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.045277\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.115375\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.020006\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.175460\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.026715\n",
      "\n",
      "Test set: Average loss: 0.0396, Accuracy: 9875/10000 (98.75%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.025509\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.011759\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.106594\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.104405\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.036126\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.015332\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.089844\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.010575\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.058466\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.028794\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.026425\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.057356\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.120356\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.075698\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.109601\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.181858\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.032184\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.001877\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.034018\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.018121\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.027470\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.053319\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.089364\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.008268\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.008961\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.084152\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.009610\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.063254\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.035114\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.019973\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.033968\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.051138\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.054249\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.115970\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.001584\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.020756\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.026310\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.042754\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.012568\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.004715\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.038032\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.010974\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.063887\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.022119\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.005036\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.031600\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.036275\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.160566\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.040328\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.065715\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.043953\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.035721\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.064542\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.056264\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.020290\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.020580\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.050520\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.065785\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.195424\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.034588\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.047124\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.231019\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.024102\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.014340\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.041664\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.050049\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.044092\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.183760\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.058620\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.023244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.007370\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.120918\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.064740\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.050492\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.024095\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.073057\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.014491\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.059459\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.037351\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.111353\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.068762\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.057042\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.019366\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.136049\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.026570\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.040745\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.052481\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.123018\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.092035\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.004999\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.127238\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.020313\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.127278\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.065323\n",
      "\n",
      "Test set: Average loss: 0.0330, Accuracy: 9896/10000 (98.96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.50, pruner_model=L2NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3ebb279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0330, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "elapsed time:  1.4415838718414307\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (16, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 16, 26, 26) |  97344  |   160   |\n",
      "|   1   | conv2 | Conv2d | (32, 16, 3, 3) | (3, 16, 26, 26) | (3, 32, 24, 24) | 2654208 |   4640  |\n",
      "|   2   | fc1   | Linear |   (64, 4608)   |    (3, 4608)    |     (3, 64)     |  294912 |  294976 |\n",
      "|   3   | fc2   | Linear |    (10, 64)    |     (3, 64)     |     (3, 10)     |   640   |   650   |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 3047104\n",
      "#Params total: 300426\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.15%\n",
      "Finetuned model FLOPs 3.05 M, #Params: 0.30M, Accuracy:  98.96%\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c97fbc",
   "metadata": {},
   "source": [
    "## L2 Norm Pruner (Config-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f429c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): PrunerModuleWrapper(\n",
      "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (conv2): PrunerModuleWrapper(\n",
      "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): PrunerModuleWrapper(\n",
      "    (module): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.25\n",
      "conv2  sparsity :  0.25\n",
      "fc1  sparsity :  0.25\n",
      "[2022-10-02 15:09:27] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mreplace linear with new in_features: 2304, out_features: 32\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mreplace linear with new in_features: 32, out_features: 10\u001b[0m\n",
      "[2022-10-02 15:09:27] \u001b[32mspeedup done\u001b[0m\n",
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=2304, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.031562\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.607316\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.451593\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.390230\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.472725\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.280631\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.371784\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.233854\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.263459\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.278436\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.295606\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.391444\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.273623\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.313997\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.207529\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.120155\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.247253\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.245741\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.190394\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.177856\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.154368\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.169631\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.230972\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.448000\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.200809\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.223009\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.205101\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.237915\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.251633\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.155057\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.345881\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.200972\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.108539\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.219174\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.322472\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.332915\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.188112\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.149700\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.218891\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.244465\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.533466\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.271149\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.226816\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.229463\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.060795\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.235517\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.142299\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.074750\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.178893\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.132249\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.328950\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.264563\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.308668\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.351982\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.208731\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.206730\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.236634\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.220543\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.547962\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.210847\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.114163\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.132352\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.047303\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.231264\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.198116\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.156051\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.098072\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.239080\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.105429\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.127447\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.336975\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.406137\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.270680\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.107645\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.123886\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.160147\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.131363\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.054097\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.294468\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.143337\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.103056\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.153256\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.122182\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.112857\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.108327\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.251190\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.186000\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.106161\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.163094\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.120254\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.192263\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.114255\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.241283\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.174680\n",
      "\n",
      "Test set: Average loss: 0.0518, Accuracy: 9851/10000 (98.51%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.136690\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.125706\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.180180\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.211048\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.333227\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.266753\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.216609\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.380852\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.181887\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.152030\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.288284\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.211453\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.066446\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.115967\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.212058\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.139681\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.143613\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.161473\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.310010\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.138282\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.102567\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.295985\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.079709\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.240655\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.142088\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.267684\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.091857\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.204660\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.412143\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.169570\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.379253\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.047238\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.070920\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.245124\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.282153\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.081629\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.087290\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.108933\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.149214\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.085406\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.166602\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.111146\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.091632\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.208455\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.061397\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.162383\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.136495\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.113777\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.308482\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.088712\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.110889\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.339046\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.108496\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.308113\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.140165\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.114313\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.188557\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.076968\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.139877\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.156812\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.242385\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.231674\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.336827\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.292690\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.128477\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.069282\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.135262\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.154686\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.057774\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.367679\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.075478\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.245102\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.084421\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.214382\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.303233\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.146053\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.098750\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.104652\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.121793\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.068454\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.082595\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.191323\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.105884\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.132093\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.161850\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.208396\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.207930\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.057676\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.145200\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.259472\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.229074\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.145705\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.122369\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.144602\n",
      "\n",
      "Test set: Average loss: 0.0502, Accuracy: 9851/10000 (98.51%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.091119\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.100606\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.047717\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.153487\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.078886\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.369338\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.095193\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.149036\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.051899\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.442453\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.130017\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.072958\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.204871\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.134502\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.063988\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.165809\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.115505\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.124219\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.132778\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.115301\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.152769\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.070801\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.323545\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.089108\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.119129\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.201298\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.117026\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.113312\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.171984\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.399662\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.290773\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.299035\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.174648\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.094065\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.253690\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.291375\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.182920\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.145521\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.356723\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.072092\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.117655\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.156401\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.042474\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.330264\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.146524\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.236378\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.094627\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.179586\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.066474\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.295127\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.096181\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.139162\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.253788\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.085085\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.132421\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.157003\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.059988\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.054364\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.042295\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.334000\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.112729\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.153931\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.344820\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.126061\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.182568\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.039868\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.136237\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.077583\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.146553\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.103474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.149947\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.133011\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.155166\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.312186\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.058209\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.078298\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.038188\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.121896\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.305930\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.059002\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.087475\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.095073\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.155713\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.082304\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.183097\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.068379\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.166467\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.273065\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.065267\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.028425\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.085795\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.066844\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.210693\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.166968\n",
      "\n",
      "Test set: Average loss: 0.0488, Accuracy: 9867/10000 (98.67%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.75, pruner_model=L2NormPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8beb1923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0488, Accuracy: 9867/10000 (98.67%)\n",
      "\n",
      "elapsed time:  1.414294958114624\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape |   Input Size   |   Output Size   | FLOPs  | #Params |\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "|   0   | conv1 | Conv2d |  (8, 1, 3, 3) | (3, 1, 28, 28) |  (3, 8, 26, 26) | 48672  |    80   |\n",
      "|   1   | conv2 | Conv2d | (16, 8, 3, 3) | (3, 8, 26, 26) | (3, 16, 24, 24) | 663552 |   1168  |\n",
      "|   2   | fc1   | Linear |   (32, 2304)  |   (3, 2304)    |     (3, 32)     | 73728  |  73760  |\n",
      "|   3   | fc2   | Linear |    (10, 32)   |    (3, 32)     |     (3, 10)     |  320   |   330   |\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "FLOPs total: 786272\n",
      "#Params total: 75338\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.15%\n",
      "Finetuned model FLOPs 0.79 M, #Params: 0.08M, Accuracy:  98.67%\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe31032",
   "metadata": {},
   "source": [
    "## FPGM Pruner (Config-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beac18dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): PrunerModuleWrapper(\n",
      "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (conv2): PrunerModuleWrapper(\n",
      "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): PrunerModuleWrapper(\n",
      "    (module): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.91\n",
      "conv2  sparsity :  0.91\n",
      "fc1  sparsity :  0.91\n",
      "[2022-10-02 15:10:03] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mreplace linear with new in_features: 8352, out_features: 116\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mreplace linear with new in_features: 116, out_features: 10\u001b[0m\n",
      "[2022-10-02 15:10:03] \u001b[32mspeedup done\u001b[0m\n",
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 29, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(29, 58, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=8352, out_features=116, bias=True)\n",
      "  (fc2): Linear(in_features=116, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.001220\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.201411\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.190002\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.203807\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.151359\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.137095\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.023806\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.022370\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.144257\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.001301\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.029660\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.036378\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.014626\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.209920\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.118204\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.045827\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.066254\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.018272\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.008530\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.124236\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.029206\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.020480\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.007890\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.025563\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.031030\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.067551\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.095803\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.033003\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.011796\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.007933\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.015993\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.045733\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.004930\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.006108\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.094289\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.066864\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.022348\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.004957\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.015913\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.013629\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.090896\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.006832\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.019889\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.028069\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.060897\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.022537\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.070780\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.107488\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.066866\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.119290\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.003989\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.068138\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.029398\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.059104\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.161905\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.023713\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.022527\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.036535\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.027128\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.025870\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.008899\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.054099\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.057561\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.021389\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.137860\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.131246\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.009411\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.230663\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.058571\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.107486\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.029408\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.002312\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.002905\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.007446\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.060159\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.151694\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.071838\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.010143\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.145250\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.031390\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.036265\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.090922\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.130748\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.021887\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.015586\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.256294\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.298040\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.001115\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.013999\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.006905\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.003541\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.104131\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.203713\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.008704\n",
      "\n",
      "Test set: Average loss: 0.0337, Accuracy: 9899/10000 (98.99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.015537\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.070507\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.003038\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.025902\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.073401\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.147494\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.002980\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.002008\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.017655\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.021484\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.011584\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.057049\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.016552\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.005927\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.032372\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.100044\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.028563\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.002090\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.008864\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.101974\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.005854\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.025952\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.012155\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.001687\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.004430\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.014870\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.038818\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.009707\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.041694\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.025577\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.004589\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.014318\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.008439\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.029448\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.056661\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.007942\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.135172\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.159687\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.050260\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.079929\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.017150\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.052276\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.037188\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.001314\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.122347\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.030452\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.093162\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.054723\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.066993\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.011034\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.018913\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.023040\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.047431\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.051407\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.082777\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.068123\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.003948\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.016667\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.036605\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.031833\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.167305\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.101051\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.015316\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.000470\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.016224\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.055834\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.073954\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.007320\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.061531\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.038257\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.104699\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.104304\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.202049\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.004635\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.027092\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.001185\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.016493\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.085640\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.021345\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.026003\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.007002\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.206392\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.099793\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.002407\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.004804\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.071540\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.011310\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.009229\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.045520\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.008096\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.017500\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.020762\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.003112\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.094632\n",
      "\n",
      "Test set: Average loss: 0.0300, Accuracy: 9910/10000 (99.10%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.023418\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.012628\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.174240\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.050791\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.056305\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.058662\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.116240\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.001040\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.000936\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.016226\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.001554\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.062910\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.003799\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.014903\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.015228\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.012723\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.010807\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.007398\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.263946\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.000727\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.001252\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.000510\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.000440\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.046181\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.007349\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.013044\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.091819\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.081948\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.042283\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.002696\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.011189\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.013794\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.032303\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.008526\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.033479\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.030290\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.042067\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.007785\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.023567\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.043580\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.007081\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.004643\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.141225\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.035471\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.030253\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.005189\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.184422\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.042279\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.039005\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.023043\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.005183\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.011160\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.000702\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.083434\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.100469\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.000911\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.009465\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.034687\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.006358\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.007271\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.036241\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.000469\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.063869\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.019976\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.012060\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.006374\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.012952\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.004697\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.003346\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.019616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.013300\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.005028\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.029889\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.013676\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.008938\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.058101\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.012759\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.007588\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.068231\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.123900\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.016761\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.085369\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.077112\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.068263\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.017820\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.071562\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.028274\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.029422\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.017047\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.007606\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.001880\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.002714\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.000572\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.006649\n",
      "\n",
      "Test set: Average loss: 0.0305, Accuracy: 9907/10000 (99.07%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.10, pruner_model=FPGMPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5358117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0305, Accuracy: 9907/10000 (99.07%)\n",
      "\n",
      "elapsed time:  1.5428528785705566\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (29, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 29, 26, 26) |  176436 |   290   |\n",
      "|   1   | conv2 | Conv2d | (58, 29, 3, 3) | (3, 29, 26, 26) | (3, 58, 24, 24) | 8719488 |  15196  |\n",
      "|   2   | fc1   | Linear |  (116, 8352)   |    (3, 8352)    |     (3, 116)    |  968832 |  968948 |\n",
      "|   3   | fc2   | Linear |   (10, 116)    |     (3, 116)    |     (3, 10)     |   1160  |   1170  |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 9865916\n",
      "#Params total: 985604\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.15%\n",
      "Finetuned model FLOPs 9.87 M, #Params: 0.99M, Accuracy:  99.07%\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e2bfe",
   "metadata": {},
   "source": [
    "## FPGM Pruner (Config-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7323ada8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): PrunerModuleWrapper(\n",
      "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (conv2): PrunerModuleWrapper(\n",
      "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): PrunerModuleWrapper(\n",
      "    (module): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.75\n",
      "conv2  sparsity :  0.75\n",
      "fc1  sparsity :  0.75\n",
      "[2022-10-02 15:10:50] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mreplace linear with new in_features: 6912, out_features: 96\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mreplace linear with new in_features: 96, out_features: 10\u001b[0m\n",
      "[2022-10-02 15:10:50] \u001b[32mspeedup done\u001b[0m\n",
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 24, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=6912, out_features=96, bias=True)\n",
      "  (fc2): Linear(in_features=96, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.016102\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.139631\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.200059\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.132061\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.014751\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.038290\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.059072\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.002524\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.015834\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.015939\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.109360\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.039247\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.063452\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.105074\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.094425\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.005782\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.065634\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.024001\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.055702\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.049746\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.095621\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.042686\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.258500\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.003086\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.048186\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.028440\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.017358\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.012703\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.127340\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.136824\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.182160\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.075249\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.070632\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.031669\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.020504\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.004860\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.021444\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.059594\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.118340\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.009958\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.020804\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.026755\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.029465\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.084860\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.020967\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.078020\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.010014\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.127558\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.016765\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.034304\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.001089\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.217941\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.131508\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.010015\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.059499\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.035057\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.008935\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.117827\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.127309\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.027967\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.036635\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.091102\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.071104\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.036775\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.097486\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.034542\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.016539\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.387007\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.024709\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.087001\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.010511\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.059855\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.108243\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.024352\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.009801\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.185910\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.019912\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.043555\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.124318\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.003639\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.048826\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.120998\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.082513\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.026776\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.021299\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.154409\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.133825\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.202647\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.054200\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.093347\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.124429\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.011056\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.017194\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.010738\n",
      "\n",
      "Test set: Average loss: 0.0353, Accuracy: 9894/10000 (98.94%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.021543\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.028259\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.011762\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.121890\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.013607\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.025918\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.141828\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.030704\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.155302\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.031099\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.037227\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.009850\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.001239\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.005878\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.040797\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.003821\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.050631\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.007251\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.039537\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.048085\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.003295\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.026589\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.108617\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.018459\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.000672\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.029685\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.012796\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.009078\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.056329\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.083408\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.175253\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.160457\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.022862\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.038052\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.043475\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.055906\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.002254\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.004866\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.006871\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.014083\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.054205\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.015361\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.090018\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.006373\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.071447\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.052525\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.035576\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.023953\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.008030\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.041569\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.018581\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.007153\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.051273\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.125609\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.011289\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.003269\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.045109\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.048160\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.010842\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.043776\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.026771\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.023466\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.009482\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.066842\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.091253\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.088365\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.039048\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.102328\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.024846\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.056397\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.048473\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.033804\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.043223\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.024368\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.070543\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.048620\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.026607\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.008358\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.007892\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.120972\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.003642\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.002993\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.035610\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.018664\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.051373\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.007464\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.005196\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.057104\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.065668\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.012273\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.097606\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.086775\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.003184\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.170629\n",
      "\n",
      "Test set: Average loss: 0.0340, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.016058\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.049594\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.127554\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.046511\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.006472\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.110845\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.027760\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.011199\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.009976\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.007704\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.004143\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.003739\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.086248\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.028861\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.009641\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.038713\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.121769\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.033139\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.003235\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.005099\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.001624\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.001845\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.029347\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.047449\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.013164\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.068880\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.243614\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.058558\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.016896\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.108206\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.038595\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.007686\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.047350\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.021160\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.037595\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.001187\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.011397\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.026856\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.065276\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.085758\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.099418\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.079979\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.010689\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.056957\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.011085\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.097417\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.011119\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.004504\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.010642\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.151216\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.012424\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.034305\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.005717\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.079815\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.011259\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.112451\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.084396\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.044152\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.016895\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.002568\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.113355\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.130994\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.012829\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.002730\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.006997\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.014021\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.038732\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.003237\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.034287\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.013105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.007916\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.176644\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.058762\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.040165\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.026047\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.029064\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.063193\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.072968\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.010320\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.057081\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.010273\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.039747\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.094514\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.004035\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.013004\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.105446\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.004987\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.015185\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.030016\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.009363\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.001400\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.001457\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.044933\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.000837\n",
      "\n",
      "Test set: Average loss: 0.0312, Accuracy: 9913/10000 (99.13%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.25, pruner_model=FPGMPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e87189c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0312, Accuracy: 9913/10000 (99.13%)\n",
      "\n",
      "elapsed time:  1.653378963470459\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (24, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 24, 26, 26) |  146016 |   240   |\n",
      "|   1   | conv2 | Conv2d | (48, 24, 3, 3) | (3, 24, 26, 26) | (3, 48, 24, 24) | 5971968 |  10416  |\n",
      "|   2   | fc1   | Linear |   (96, 6912)   |    (3, 6912)    |     (3, 96)     |  663552 |  663648 |\n",
      "|   3   | fc2   | Linear |    (10, 96)    |     (3, 96)     |     (3, 10)     |   960   |   970   |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 6782496\n",
      "#Params total: 675274\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.15%\n",
      "Finetuned model FLOPs 6.78 M, #Params: 0.68M, Accuracy:  99.13%\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e286d15",
   "metadata": {},
   "source": [
    "## FPGM Pruner (Config-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01e9e0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): PrunerModuleWrapper(\n",
      "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (conv2): PrunerModuleWrapper(\n",
      "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): PrunerModuleWrapper(\n",
      "    (module): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.5\n",
      "conv2  sparsity :  0.5\n",
      "fc1  sparsity :  0.5\n",
      "[2022-10-02 15:11:32] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 15:11:32] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mreplace linear with new in_features: 4608, out_features: 64\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mreplace linear with new in_features: 64, out_features: 10\u001b[0m\n",
      "[2022-10-02 15:11:33] \u001b[32mspeedup done\u001b[0m\n",
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=4608, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.723701\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.096251\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.090161\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.078753\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.067995\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.085111\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.120897\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.099771\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.015471\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.007156\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.245937\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.121848\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.066174\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.045766\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.063813\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.144056\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.098800\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.059080\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.103523\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.146953\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.049401\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.214163\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.027450\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.050668\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.078696\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.071239\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.088366\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.125742\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.313707\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.006469\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.024113\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.047210\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.039888\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.199023\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.024324\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.068644\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.045739\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.082876\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.149349\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.007103\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.195173\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.182734\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.041018\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.011166\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.109442\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.039558\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.017144\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.014985\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.050631\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.049309\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.056775\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.156428\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.114607\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.218344\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.059928\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.061313\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.196468\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.109626\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.128625\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.214688\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.084489\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.018222\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.046518\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.115841\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.060085\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.067544\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.027396\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.035190\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.029419\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.085718\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.226528\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.202616\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.705871\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.094189\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.042189\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.033199\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.049258\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.173441\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.013703\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.097429\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.048784\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.046099\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.064378\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.103773\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.050682\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.024459\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.055947\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.041574\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.018530\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.027963\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.067677\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.019523\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.019555\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.047465\n",
      "\n",
      "Test set: Average loss: 0.0385, Accuracy: 9878/10000 (98.78%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.088049\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.032227\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.031696\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.026016\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.025335\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.046050\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.027216\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.022011\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.099938\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.012753\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.011279\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.017470\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.100142\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.129813\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.015897\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.075425\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.023343\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.081819\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.052196\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.072057\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.022183\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.038439\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.031733\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.027370\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.084272\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.022923\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.024149\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.018850\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.082178\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.040964\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.032424\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.059203\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.021547\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.024492\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.197698\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.051097\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.075517\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.073474\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.026130\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.227003\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.031997\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.012475\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.063280\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.030483\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.052831\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.008893\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.043250\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.001639\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.081461\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.090533\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.115074\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.017157\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.066875\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.091064\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.046178\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.025110\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.087336\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.072771\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.015677\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.104292\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.112390\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.056266\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.086345\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.161085\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.061551\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.007888\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.053472\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.095268\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.136916\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.007851\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.060878\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.275640\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.012046\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.058822\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.008047\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.051721\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.095744\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.010426\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.039437\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.008726\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.029672\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.053815\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.084644\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.130329\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.053632\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.062393\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.142498\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.012987\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.008600\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.091462\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.020218\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.021773\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.080615\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.034132\n",
      "\n",
      "Test set: Average loss: 0.0386, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.063864\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.183894\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.003800\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.072152\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.065450\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.084261\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.120303\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.154030\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.019368\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.101818\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.139312\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.022131\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.052403\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.050463\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.022045\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.107598\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.026032\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.021019\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.006589\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.149785\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.021076\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.106846\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.045897\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.012564\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.056052\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.032064\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.027499\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.024334\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.052562\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.066340\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.140012\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.205038\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.111576\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.041872\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.015004\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.171136\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.084811\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.054343\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.056866\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.046732\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.016287\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.008074\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.025369\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.055517\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.118702\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.063692\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.052069\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.008634\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.020195\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.080532\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.091957\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.127619\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.086334\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.027075\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.046304\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.033108\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.068262\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.006340\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.108037\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.094633\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.048314\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.026135\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.100864\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.076881\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.094107\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.050735\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.069550\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.019967\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.058375\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.008560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.158362\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.001614\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.031729\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.012695\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.011649\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.012408\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.018029\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.085527\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.008531\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.071454\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.201498\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.037550\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.051854\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.162102\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.013165\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.059312\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.018439\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.048003\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.059643\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.017936\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.056308\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.038260\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.038422\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.067827\n",
      "\n",
      "Test set: Average loss: 0.0341, Accuracy: 9888/10000 (98.88%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.50, pruner_model=FPGMPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80b59249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0341, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "elapsed time:  1.509709358215332\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs  | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "|   0   | conv1 | Conv2d | (16, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 16, 26, 26) |  97344  |   160   |\n",
      "|   1   | conv2 | Conv2d | (32, 16, 3, 3) | (3, 16, 26, 26) | (3, 32, 24, 24) | 2654208 |   4640  |\n",
      "|   2   | fc1   | Linear |   (64, 4608)   |    (3, 4608)    |     (3, 64)     |  294912 |  294976 |\n",
      "|   3   | fc2   | Linear |    (10, 64)    |     (3, 64)     |     (3, 10)     |   640   |   650   |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+---------+---------+\n",
      "FLOPs total: 3047104\n",
      "#Params total: 300426\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.15%\n",
      "Finetuned model FLOPs 3.05 M, #Params: 0.30M, Accuracy:  98.88%\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f3394",
   "metadata": {},
   "source": [
    "## FPGM Pruner (Config-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94c8614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): PrunerModuleWrapper(\n",
      "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (conv2): PrunerModuleWrapper(\n",
      "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): PrunerModuleWrapper(\n",
      "    (module): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Showing the masks sparsity\n",
      "conv1  sparsity :  0.25\n",
      "conv2  sparsity :  0.25\n",
      "fc1  sparsity :  0.25\n",
      "[2022-10-02 15:12:12] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32minfer module masks...\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate mask for .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate mask for .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate mask for .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate mask for dropout1\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate mask for .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate mask for .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate mask for dropout2\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate mask for .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.11\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate the indirect sparsity for the dropout2\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate the indirect sparsity for the .aten::relu.10\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.9\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate the indirect sparsity for the dropout1\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate the indirect sparsity for the .aten::max_pool2d.8\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate the indirect sparsity for the .aten::relu.7\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate the indirect sparsity for the .aten::relu.6\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mreplace module (name: dropout1, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mreplace linear with new in_features: 2304, out_features: 32\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mreplace module (name: dropout2, op_type: Dropout)\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mreplace linear with new in_features: 32, out_features: 10\u001b[0m\n",
      "[2022-10-02 15:12:12] \u001b[32mspeedup done\u001b[0m\n",
      "Model after speedup\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=2304, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.468065\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.767191\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.629752\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.374973\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.368472\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.215773\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.346239\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.249841\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.311342\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.278417\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.137269\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.264053\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.209263\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.251151\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.290117\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.383940\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.269724\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.193731\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.264505\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.207901\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.218671\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.193665\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.339103\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.312199\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.192544\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.379883\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.194988\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.270647\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.185014\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.172261\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.268253\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.192666\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.072985\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.262205\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.200162\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.120644\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.073216\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.169712\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.153830\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.218968\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.355743\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.145714\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.317089\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.224197\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.180070\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.229842\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.313273\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.241208\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.281357\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.159119\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.174229\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.196099\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.245326\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.071925\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.116677\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.042526\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.230240\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.182750\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.122570\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.163178\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.215098\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.326237\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.397126\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.172508\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.218590\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.181170\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.140681\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.088024\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.234777\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.301801\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.205593\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.169705\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.102307\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.259323\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.073221\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.345141\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.320579\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.258263\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.128269\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.537273\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.247770\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.296792\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.151257\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.081654\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.432186\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.153226\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.110438\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.209521\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.343715\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.138356\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.141870\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.091072\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.233342\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.141205\n",
      "\n",
      "Test set: Average loss: 0.0581, Accuracy: 9832/10000 (98.32%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.275539\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.043117\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.095753\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.079458\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.128542\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.192832\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.096857\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.236074\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.098474\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.310077\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.061104\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.112351\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.496540\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.121864\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.207250\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.408760\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.160663\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.154353\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.074998\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.133837\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.134927\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.182194\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.294259\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.112061\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.041202\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.186813\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.150025\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.203045\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.107318\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.118540\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.312865\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.138305\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.074008\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.260493\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.174344\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.204492\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.161302\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.408474\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.110584\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.119817\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.093740\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.085028\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.165774\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.057445\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.132135\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.051123\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.109686\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.132912\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.068915\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.144832\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.140406\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.096350\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.115212\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.137896\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.124329\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.314120\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.094274\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.235525\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.273058\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.102457\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.310214\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.406312\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.181221\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.158439\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.231952\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.222582\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.124936\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.230453\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.149636\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.227894\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.257814\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.102934\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.049511\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.143118\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.121990\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.188125\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.098977\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.220098\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.174363\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.177087\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.136131\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.117301\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.153436\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.213231\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.165711\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.180814\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.183956\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.278677\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.177426\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.215041\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.040995\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.144611\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.406264\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.056905\n",
      "\n",
      "Test set: Average loss: 0.0532, Accuracy: 9848/10000 (98.48%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.070593\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.256897\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.364688\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.282637\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.119773\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.121916\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.103777\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.179240\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.229281\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.124401\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.214898\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.097361\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.126050\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.083426\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.046370\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.105550\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.189729\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.142277\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.189470\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.176002\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.165473\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.047607\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.087843\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.027670\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.162316\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.171006\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.361088\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.114777\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.181119\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.058662\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.131594\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.082263\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.158265\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.087438\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.418039\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.093019\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.121383\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.081848\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.235422\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.135182\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.445671\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.234449\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.164154\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.056983\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.148990\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.034228\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.091537\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.085273\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.107185\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.069672\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.080216\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.164579\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.368035\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.073985\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.118212\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.050372\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.094174\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.039326\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.143796\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.127544\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.096573\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.085433\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.235350\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.142964\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.045642\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.225664\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.112290\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.054415\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.128983\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.100596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.105211\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.110291\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.226972\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.096863\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.074552\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.021060\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.140170\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.111406\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.473907\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.269903\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.179419\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.332203\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.125220\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.250815\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.030172\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.200142\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.110928\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.081539\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.325810\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.282949\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.121099\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.082318\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.171338\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.243418\n",
      "\n",
      "Test set: Average loss: 0.0513, Accuracy: 9856/10000 (98.56%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pruned_model = pruner_function(sparsity_per_layer=0.75, pruner_model=FPGMPruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "696a4157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0513, Accuracy: 9856/10000 (98.56%)\n",
      "\n",
      "elapsed time:  1.4704921245574951\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape |   Input Size   |   Output Size   | FLOPs  | #Params |\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "|   0   | conv1 | Conv2d |  (8, 1, 3, 3) | (3, 1, 28, 28) |  (3, 8, 26, 26) | 48672  |    80   |\n",
      "|   1   | conv2 | Conv2d | (16, 8, 3, 3) | (3, 8, 26, 26) | (3, 16, 24, 24) | 663552 |   1168  |\n",
      "|   2   | fc1   | Linear |   (32, 2304)  |   (3, 2304)    |     (3, 32)     | 73728  |  73760  |\n",
      "|   3   | fc2   | Linear |    (10, 32)   |    (3, 32)     |     (3, 10)     |  320   |   330   |\n",
      "+-------+-------+--------+---------------+----------------+-----------------+--------+---------+\n",
      "FLOPs total: 786272\n",
      "#Params total: 75338\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.15%\n",
      "Finetuned model FLOPs 0.79 M, #Params: 0.08M, Accuracy:  98.56%\n"
     ]
    }
   ],
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
